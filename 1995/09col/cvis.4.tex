\section{The Cortical Basis of Color Appearance}

\subsection*{Clinical studies}
In 1974 J.C. Meadows reviewed case studies of fourteen patients who
had lost their ability to see colors due to a brain injury.  For some
patients, the colors of objects appeared wrong.  Other patients saw
the world entirely in shades of gray.  Yet, these patients still had
good visual acuity.

The syndrome Meadows reviewed, which I will call {\em cerebral
dyschromatopsia}, had been described in reports spanning a
century\footnote{ Some of the terms used to describe color loss vary
between authors.  The terms trichromacy, dichromacy and monochromacy
are precise, referring to the number of primary lights necessary to
complete the color matching experiment.  Some authors use the phrase
{\em cerebral achromatopsia}, meaning ``without color vision'', to
describe a loss of color vision while others use cerebral
dyschromatopsia.  I prefer the second term because in these cases
insensitivity to hue is often not complete and because these patients
still distinguish the colors white and black.  When the behavioral
evidence warrants it, one might append a modifier, such as {\em
monochromatic} dyschromatopsia, to describe the the color loss more
precisely.}  (Zeki, 1990).  But, the cases were rare, poor methods
were used to study the patients, and the color loss was not
well-dissociated from other visual deficits.  Consequently, at the
time Meadows wrote his review, several well-known investigators had
expressed doubt about even the existence of cerebral
dyschromatopsia\footnote{ In his book and in a long article, Zeki
argued that the skepticism concerning cerebral dyschromatopsia was
caused by their acceptance of a profoundly misguided theory concerning
the significance of visual area V1.  I agree with Meadows' gentler
assessment; the early evidence in support of cerebral dyschromatopsia
is spotty and poorly argued.  There was room for some
skepticism.}(e.g. Teuber, et al., 1960).  By bringing together a
number of new cases and studying them with much better methods,
Critchley (1965), Meadows (1974), Zeki (1990) and others (e.g. Green
and Lesell, 1977; Domasio, et al., 1980; Victor, 1989; Mollon, 1980;
Heywood et al., 1987; 1992) have removed any doubt about the existence
and significance of the syndrome.

\subsection*{Congenital Monochromacy. }
Usually, observers are dichromats or monochromats because they are
missing one of the cone photopigments (see e.g.  Alpern 1964; Smith
and Pokorny 1972).  There are also reports of congenital
cone monochromacy of central origin.  In a thorough and fascinating
study, R. A. Weale (1953) searched England for individuals who (a)
could not tell color photographs from black and white, (b) were not
photophobic, and (c) had good visual acuity.  (Requirements (b) and
(c) eliminated rod monochromats).  Weale found three cone
monochromats, that is individuals who could adjust the intensity of a
single primary light to match the appearance of any other test light.
Yet, based on direct measurements of the photopigment in the eye of
one of the observers, as well as behavioral measurements, some of
these cone monochromats were shown to have more than one cone
photopigment (Weale, 1959; Gibson, 1962; see also Alpern, 1974).
Hence, Weale's subjects had a congenital dyschromatopsia caused by
deficiencies central to the photopigments.  At present, we know little
more about them.

\subsection*{Regularities of the Cerebral Dyschromatopsia Syndrome.  }
When color loss arises from damage to the brain, the distortion of
color appearance can take several forms.  In some cases, patients
report that colors have completely lost their saturation and hue and
the world becomes gray.  In other cases, color appearance may become
desaturated.  Some observer can perform some simple color
discrimination tasks, but they report that the colors of familiar
objects do not appear right.  In many cases the loss is permanent, but
there are also reports of transient dyschromatopsia.  For example,
Lawden and Cleland (1993) recently reported on the case of a woman who
suffers from migraines.  During the migraine attacks, her world
becomes transiently colorless.

The variability in the case studies suggest that there are a variety
of mechanisms that may disturb color appearance.  Across this
variability, however, there are also some regularities.  First,
Meadows (1974) observed that every patient with dyschromatopsia was
blind in some portion of the upper visual field.

Second, Meadows examined the reverse correlation: do patients with
purely upper visual field losses tend to have cerebral
dyschromatopsia?  In the literature, he found twelve patients with a
purely upper visual field loss, seven had dyschromatopsia.  Of sixteen
patients with a purely lower visual field loss, none had
dyschromatopsia.  In humans, the upper visual field is represented
along the lower part of the calcarine sulcus
(Chapter~\ref{chapter:Cortex}).  The correlation between field loss
and dyschromatopsia suggests that the damage that leads to
dyschromatopsia is either near the lower portion of the calcarine or
somewhere along the path traced out by the nerve fibers whose signal
enters the lower portion of the calcarine cortex.

Third, many of the patients suffer from a syndrome called {\em
prosopagnosia}, the inability to recognize familiar faces.  Twelve of
the fourteen patients described by Meadows had this syndrome.  The
patient with migraines also has transient prosopagnosia (Lawden and
Cleland, 1993).  The co-occurrence of dyschromatopsia and
prosopagnosia suggests that the neural mechanisms necessary for recall
of familiar faces and color are located close to one another or that they
rely on the same visual signal.

Based on his review of the literature, Meadows concluded
that~\footnote{ As S. Zeki points out, Meadows' conclusion echoes a
disputed suggestion made a century earlier.  While studying a patient
who reported a loss of color vision, the French physician, Verrey
concluded,
\begin{quote}
Le centre du sense chromatique se trouverait dans la partie la plus
inferieure du lobe occipital, probablement dans la partie posterieure
des plis lingual et fusiforme.  (Verry, 1888, cited in Zeki, 1990,
p. 1722) [Translation: The center of the chromatic sense will be found
in the inferior part of the occipital lobe, probably in the posterior
part of the lingual and fusiform gyrus].
\end{quote}
}.
\begin{quote}
The evidence on localization in cases of cerebral achromatopsia points
to the importance of bilateral, inferiorly placed, posterior lesions
of both cerebral hemispheres. (Meadows, 1974, p. 622)
\end{quote}

\subsection*{Behavioral studies of patients with cerebral dyschromatopsia.  }
% Rizzo patient fails Ishihara plates.
% Mollon's failed the plates
% Critchley and Korner failed the plates
% Sacks patient failed
% Alpern's monochromat failed the Ishihara plates
% Meadows patient read the plates Victor's patient read the plates

Patients with cerebral dyschromatopsia often fail to identify any of
the test patterns on the Ishihara plates~\footnote{But, Meadows (1974)
and Victor et al. (1987) describe patients who could read all of the
plates.}.  Mollon et al. (1980) reported on a patient who failed to
identify the targets on the Ishihara plates
(Chapter~\ref{chapter:wavelength}) at reading distance, but who could
distinguish the targets when the plates were viewed from 2 meters.  At
the 2 meter viewing distance, the neutral areas separating the target
and background are barely visible and the target and background appear
contiguous.  Twelve years after the original study, Heywood et
al. (1992) replicated the finding on the same patient.  They also
showed that the patient can discriminate contiguous colors, but not
colors separated by a gray stripe.  Hence, in this patient cerebral
dyschromatopsia involves color and pattern together (see also Victor
et al., 1987).

% Figure 4 in Meadows (1974), page. 630.
\begin{figure}
\centerline{
 \psfig{figure=../09col/fig/meadows.ps ,clip= ,width=5.5in} }
\caption[Farnsworth Test in cerebral dyschromatopsia]{
{\em Results of the Farnsworth test measured on a patient suffering
cerebral dyschromatopsia.} The patients error scores are high in all
hue directions.  This pattern of scores is not consistent with any of
the usual pattern of errors observed by cone dichromats who are
missing one of their cone photopigments (Source: Meadows, 1974).  
}
\label{f8:meadows} 
\end{figure}

Cerebral dyschromatopsics score quite poorly on the Farnsworth-Munsell
hue test (see Chapter~\ref{chapter:wavelength}).  The pattern of
errors does not correspond to the errors made by any class of
dichromat.  The results of the test of one such patient
is shown in Figure~\ref{f8:meadows}.  The errors are large in all
directions though there is some hint that the errors may be somewhat
larger in the blue and yellow portions of the hue circle.

\subsection*{How many cone types are functional?  }
The patients' errors on the Ishihara color plates and the
Farnsworth-Munsell hue test are not consistent with a visual pigment
loss.  Nonetheless, we cannot tell from their performance on these
tests whether the separate cone classes are functioning or whether the
loss of color perception is due, in part, to cone dysfunction.

Gibson (1961; Alpern, 1974; Mollon et al., 1980) developed a
behavioral test to infer whether the patients with cerebral
dyschromatopsia had more than a single class of functioning cones.
The logic of their behavioral test is based on the fact the cone
signals are scaled to correct for changes in the ambient lighting
conditions.  For example, in the presence of a long-wavelength
background, the sensitivity of the $\Red$ cones is suppressed while
the sensitivity of the $\Blue$ cones remains unchanged.

Now, suppose a subject has only a single type of cone.  For
this observer wavelength sensitivity is determined by the spectral
sensitivity a single cone photopigment.  Changes of the background
illumination will not change the observer's relative wavelength
sensitivity.  This is the situation for normal observers under
scotopic viewing conditions when we see only through the rods.  Under
scotopic conditions wavelength sensitivity is determined by the rhodopsin
photopigment; changing the background does not change in the relative
sensitivity to different test wavelengths~\footnote{ In a beautiful
series of experiments, W.S. Stiles(1939; 1959; 1979) studied how
sensitivity varies as one changes the wavelength and intensity of a
test and background lights.  He developed a penetrating analysis of
this experimental paradigm and identified candidates processes which
he believed might describe photoreceptor adaptation.  He referred to
these processes as $\pi$-mechanisms, ``p'' for process and $\pi$ for
p.}.

If an individual has two functional cone classes, however, changes in
the sensitivity of one cone class relative to the other will change
the behavioral wavelength sensitivity.  Hence, we can detect the
presence of two cone classes by measuring wavelength sensitivity on
two different backgrounds and noting a change in the observer's
relative wavelength sensitivity.

Mollon et al. (1980) measured a cerebral dyschromatopsic's relative
wavelength sensitivity to test wavelengths (510nm and 640nm) on two
different backgrounds (510nm and 650nm).  I have replotted their data
in Figure~\ref{f8:mollon}.  When the background changes, the relative
test wavelength sensitivity changes showing that the subject has at
least two functional cone classes, like Weale's and Alpern's
congenital monochromats.
\begin{figure}
\centerline{
 \psfig{figure=../09col/fig/mollon.ps ,clip= ,width=5.5in} }
\caption[Mollon data.]{ 
{\em Experimental demonstration that a patient with cerebral
dyschromatopsia has more than a single functioning cone class.} (a)
The patient's threshold sensitivity was measured to two monochromatic
test lights on two different backgrounds.  The change in background
illumination changed the patient's relative wavelength sensitivity.
(b) The results of performing the same experiment on a normal observer
are shown.  The results from the normal observer and the patient are
quite similar (Source: Mollon et al., 1980).  }
\label{f8:mollon} 
\end{figure}

% What have we learned from all this?  
Clinical studies of cerebral dyschromatopsia shows that central
lesions can disturb color vision severely, while sparing many other
aspects of visual performance.  This clinical syndrome suggests that
some of the neural mechanisms essential to the sensation of color
appearance may be anatomically separate from the mechanisms required
for other visual tasks, such as acuity, motion and depth perception.
But, clinical lesions are not neat and orderly, and the syndrome of
cerebral dyschromatopsia is quite varied.  Alternative hypotheses, for
example that neurons carrying color information are more susceptible
to stroke damage than other neurons, are also consistent with the
clinical observations (Mollon et al., 1980).  To pursue the question
of the neural representation of color information, we need to consider
other forms of evidence concerning the localization of color
appearance.

\subsection*{Physiological studies of color appearance.}
Much of the agenda for modern research on the cortical representation
of color appearance has been set by Zeki via a hypothesis he calls
{\em functional segregation} (Zeki, 1974, 1993;
Chapter~\ref{chapter:Cortex}).

Zeki argues that there is a direct correlation between the neural
responses in cortical areas beyond V1 and various perceptual features,
such as color, motion and form.  This is not the only hypothesis we
might entertain for the relationship between brain structures and
perceptual function.  An alternative view has been expressed by
Livingstone and Hubel (1984; 1987) who argued that perceptual function
can be localized to groups of neurons residing within single visual
areas.  Specifically, they have argued that differences in the density
of the enzyme cytochrome oxidase within cell bodies serves as a clue
to the localization of perceptual processing (see
Chapter~\ref{chapter:Cortex}).  This criterion for identifying neural
segregation of function seems relevant in areas V1 and V2 since the
the anatomical interconnections between these areas appear to respect
the differences in cytochrome oxidase density (Burkhalter, 1989).

Livingstone and Hubel's hypothesis need not conflict with Zeki's since
information may be interwined within peripheral visual areas only to
be segregated later.  But, the presence of subdivisions within areas
V1 and V2 raise the question of whether more detailed study might not
reveal functional subdivisions within areas V4 and MT as well (see
e.g. Born and Tootell, 1992).

The principle line of evidence used to support Zeki's hypothesis of
functional segregation is Barlow's neuron doctrine: namely, that the
receptive field of a neuron corresponds to the perceptual experience
the animal will have when the neuron is excited
(Chapter~\ref{chapter:Cortex}).  Based on this doctrine,
neurophysiologists frequently assume that neurons with spatially
oriented receptive fields are responsible for the perception of form;
neurons that are inhibited by some wavelengths and excited by others
are responsible for opponent-color percepts; neurons with motion
selective receptive fields are responsible for motion perception.

Zeki's suggestion that monkey area V4 is a color center and area MT is
a motion center is based on differences in the receptive field
properties of neurons in these two areas.  The overwhelming majority
of neurons in area MT show motion direction selectivity.  Zeki
reported that many neurons in area V4 reported an unusual wavelength
selectivity (Zeki, 1973, 1980, 1990).

As we have already seen, qualitative observations concerning receptive
neural wavelength selectivity is not a firm basis to establish these
neurons as being devoted mainly to color.  For example, the vast
majority of neurons in the lateral geniculate nucleus respond with
opponent-signals, and these neurons have no orientation selectivity.
Yet, we know that these neurons surely represent color, form and
motion information.

Moreover, the quality of the receptive field measurements in area V4
has not achieved the same level of precision as measurements in the
retina or area V1.  Because these cells appear to be highly nonlinear,
there are no widely agreed upon methods for fully characterizing their
responses.  And, there have been disputes concerning even the
qualitative properties of area V4 receptive fields.  For example,
Desimone and Schein (1987) report that many cells are selective to
orientation, direction of motion, and spatial frequency.  Like Zeki,
these authors too accept the basic logic of the neuron doctrine.  They
conclude from the variation of receptive field properties that ``V4 is
not specialized to analyze one particular attribute of a stimulus;
rather, V4 appears to process both spatial and spectral information in
parallel.''  They then develop an alternative notion of the role of
area V4 and later visual areas.
\nocite{Desimone1985}

\subsection*{Reasoning about Cortex and Perception} 
While hypotheses about the role of different cortical areas in
perception are being debated, and experiments have begun, we are at
quite an early stage in our understanding of cortical function.  This
should not be too surprising, after all the scientific investigation
of the relationship between cortical responses and perception is a
relatively new scientific endeavor, perhaps less than 100 years old.
At this point in time we should expect some controversy and
uncertainty regarding the status of early hypotheses.  Much of the
controversy stems from is due to our field's inexperience in judging
which experimental measurements will prove to be a reliable source of
information and which will not.

In thinking about what we have learned about cortical function,
I find it helpful to consider these two questions:

\be

\item What do we want to know about cortical function?

\item What are the logical underpinnings of the
experimental methods we have available to determine
the relationship between cortical responses and perception?

\ee

When one discovers a new structure in the brain, it is almost
impossible to refrain from asking: what does this part of the brain
do?  Once one poses this question, the answer is naturally formulated
in terms of the {\em localization} of perceptual function.  Our
mindset becomes one of asking what happens here, rather than asking
what happens.  Hypotheses concerning the localization of function are
the usual way to begin a research program on brain function.  Moreover,
I think any fair reading of the historical literature will show that
hypotheses about what functions are localized within the brain region
serve the useful purpose of organizing early experiments and theory.

On the other hand, in those portions of the visual pathways where our
understanding is relatively mature, localization is rarely the
central issue.  We know that the retina is involved in visual
function, and we know that some features of the retinal encoding are
important for acuity, adaptation, wavelength encoding, and so forth.
Our grasp of retinal function is sufficiently powerful so that we no
longer frame questions about retinal function as a problem of
localization.  Instead, we pose problems in terms of the flow of
information; we try to understand how information is represented
and transformed within the retina.

For example, we know that information about the stimulus wavelength is
represented by the relative absorption rates of the three cone
photopigments.  The information is not localized in any simple
anatomical sense: no single neuron contains all the necessary
information, nor are the neurons that represent wavelength information
grouped together.  Perhaps, one might argue that acuity is localized
since acuity is greatest in the fovea.  Even so, acuity depends on
image formation, proper spacing of the photoreceptors, and appropriate
representation of the photoreceptors on the optic tract.  Without all
of these others components in place, the observer will not have good
visual acuity.  The important questions about visual acuity are
questions about the nature of the information and how the information
is encoded and transmitted.  That the fovea is the region of highest
acuity is important, but not a solution to the question of how we
resolve fine detail.

The most important questions about vision are those that Helmholtz
posed: What are the principles that govern how the visual pathways
make inferences from the visual image?  How do we use image
information to compute these perceptual inferences?  We seek to
understand these principles of behavior and neural representations
with the same precision as we understand color-matching and the cone
photopigments.  We begin with spatial localization of brain function
so that we can decide where to begin our work, not how to end it.

Thus, as our understanding becomes more refined we no longer formulate
hypotheses based on localization of function alone.  Instead, we use
quantitative methods to compare neural responses and and behavioral
measurements.  Mature areas of vision science relate perception and
neural response by demonstrating correlations between the information
in the neural signals and the computations applied to those signals.
The information contained in the neural response, and the
transformations applied to that information, is the essence of
perception.

\section{Summary and Conclusions}
Color appearance, like so much of vision, is an inference.  Mainly,
color is a perceptual representation of the surface reflectance of
that object.  There are two powerful obstacles that make it difficult
to infer surface reflectance from the light incident at the eye.
First, the reflected light confounds information about the surface and
illuminant.  Second, the human eye has only three types of cones to
encode a spectral signal consisting of many different wavelengths.

We began this chapter by asking what aspects of color imaging might
make it feasible to perform this visual inference.  Specifically, we
studied how surface reflectance might be estimated from the light
incident at the eye.  We concluded that it is possible to draw
accurate inferences about surface reflectance functions when the
surface and illuminant spectral curves are regular functions that can
be well-approximated by low dimensional linear models.  When the input
signals are constrained, it is possible to design simple algorithms
that use the cone absorptions to estimate accurately surface
reflectance.

Next, we considered whether human judgments of color appearance share
some of the properties used by algorithms that estimate surface
reflectance.  As a test of the correspondence between these abstract
algorithms and human behavior, we reviewed how judgments of color
appearance vary with changes in the illumination.  Experimental
results using the asymmetric color-matching method show that color
appearance judgments of targets seen under different illuminants can
be predicted by matches between scaled responses of the human cones.
The scale factor depends on the difference in illumination.  To a
large degree, these results are consistent with the general principle
we have observed many times: judgments of color appearance are
described mainly by the local contrast of the cone signals, not their
absolute level. By basing color appearance judgments on the scaled
signal, which approximates the local cone contrast, color appearance
correlates more closely with surface reflectance than with the light
incident at the eye.

Then, we turned to a more general review of the organizational
principles of color appearance.  There are two important means of
organizing color experience.  Many color representations, like the
Munsell representation, emphasize the properties of hue, saturation
and lightness.  A second organizational theme is based on Hering's
observation that red-green and blue-yellow are opponent-colors pairs,
and that we never experience these hues together in a single color.
The opponent-colors organization has drawn considerable attention with
the discovery that many neurons carry opponent-signals, increasing
their response to some wavelengths of light and decreasing in response
to others.

In recent years, there have been many creative and interesting
attempts to study the representation of color information in visual
cortex.  Most prominent amongst the hypotheses generated by this work
is the notion that opponent-colors signals are spatially localized in
the cortex.  The evidence in support of this view comes from two types
of experiments.  First, clinical observations show that certain
individuals lose their ability to perceive color although they still
retina high visual acuity. Second, studies of the receptive fields of
individual neurons suggest that opponent-colors signals are
represented in spatially localized brain areas.  These hypotheses are
new and unproven.  But, whether they are ultimately right or wrong,
these hypotheses are the important opening steps in the modern
scientific quest to understand the neural basis of conscious
experience.



