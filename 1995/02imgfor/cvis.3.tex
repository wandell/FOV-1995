\section{Lenses, Diffraction and Aberrations}

\subsection*{Lenses and Accommodation}
\label{sec1:lenses}

What prevents the optics of our eye from 
focusing the image perfectly?
To answer this question
we should consider why a lens is useful in
bringing objects to focus at all.

As a ray of light is reflected from
an object, it will travel along
along a straight line until it reaches a new material
boundary.
At that point, the ray may be either absorbed
by the new medium, reflected, or refracted.
The latter two possibilities are illustrated in 
part (a) of Figure \ref{f1:snell}.
We call the angle between the incident ray of light
and the perpendicular to the surface the {\em angle of incidence}.
The angle between the reflected ray and the perpendicular to the surface
is called the {\em angle of reflection},
and it equals the angle of incidence.
Of course, reflected light is not useful for image formation at all.
\begin{figure}
\centerline {
\psfig{figure=../02imgfor/fig/snell.ps,clip=,height=3.0in}
}
\caption[Snell's Law]{ 
{\em Snell's law.}
The solid lines indicate surface normals and the
dashed lines indicate the light ray.
(a) When a light ray passes from one medium to another,
the ray can be refracted so that
the angle of incidence
($\phi$) does not equal the angle of refraction ($\phi '$).
Instead, the angle of refraction
depends on the refractive indices of the new media
($n$ and $n'$) a relationship called
Snell's law that is defined in Equation~\ref{e1:snell}.
% (after Jenkins and White figures 1H page 15 and 2H page 30.)
(b) A prism causes two refractions of the light ray
and can reverse the ray's direction from upward to downward.
(c) A lens combines the effect of many prisms in order
to converge the rays diverging from a point source.
%(After Jenkins and White figure 1F, page 12.)
}
\label{f1:snell}
\end{figure}
\nocite{JenkinsWhite,CornsweetBook}

The useful rays for imaging must pass from the first
medium into the second.
As they pass from between the two media,
the ray's direction is {\em refracted}.
The angle between the refracted ray
and the perpendicular to the surface
is called the {\em angle of refraction}.

The relationship between the angle of incidence
and the angle of refraction was first discovered by
a Dutch astronomer and mathematician, Willebrord Snell
in 1621.
He observed that when
$\phi$ is the angle of incidence, and
$\phi '$ is the angle of refraction, then
\begin{equation}
\label{e1:snell}
\frac{ \sin \phi } { \sin \phi ' } = \frac{\nu '}{\nu }
\end{equation}
The terms $\nu '$ and $\nu$ in Equation \ref{e1:snell}
are the {\em refractive indices} of the two media.
The refractive index of an optical medium
is the ratio of the speed of light in a
vacuum to the speed of light in the optical medium.
The refractive index of glass is $1.520$, for water
the refractive index is $1.333$ and for air it is 
nearly $1.000$.
The refractive index of the human cornea is $1.376$ is quite
similar to water, which is the main content of our eyes.
% jenkins white page 190

Now, consider the consequence of applying Snell's
law twice in a row as light passes into and then
out of a prism, as illustrated in part (b) of Figure \ref{f1:snell}.
We can draw the path of the ray as it enters the prism
using Snell's law.
The symmetry of the prism and the reversibility of the
light path makes it easy to draw the exit path.
Passage through the prism bends the ray's path downward.
The prism causes the light to deviate significantly
from a straight path; the amount of the deviation
depends upon the angle of incidence and
the angle between the two sides of the prism.

We can build a lens by smoothly
combining many infintesimally
small prisms to form a convex lens,
as illustrated in part (c) of Figure \ref{f1:snell}.
In constructing such a lens,
any deviations from the smooth shape, or imperfections
in the material used to build the lens,
will cause the individual rays
to be brought to focus at slightly different
points in the image plane.
These small deviations of shape or materials
are a source of the imperfections in the image.

Objects at different depths 
are focused at different distances behind the lens.
The {\em lensmaker's equation} relates the 
distance between the source and the lens
with the distance between the image and the lens.
The lensmaker's equation relating these two distances depends on
{\em focal length} of the lens.
Call the distance from the center of the lens
to the source $d_s$, the distance
to the image $d_i$, and the focal length of the lens, $f$.
Then the lensmaker's equation is
\begin{equation}
\frac{1}{{d_s}} + \frac{1}{{d_i}} = \frac{1}{ f} .
\end{equation}
From this equation,
notice that we can measure the focal length of a convex thin lens
by using it to image a very distant object.
In that case, the term $1/{d_s}$ is zero so that the image distance
is equal to the focal length.
When I first moved to California, I spent a lot of time
measuring the focal length of the lenses in my laboratory
by going outside and imaging the sun on a piece of paper behind the lens;
the sun was a convenient source at optical infinity.
It had been a less reliable source for me in my previous home.

\begin{figure}
\centerline{
\psfig{figure=../02imgfor/fig/accommodation.ps,clip= ,height=3.0in}
}
\caption[Depth of Field in the Human Eye]{
{\em Depth of field of the human eye.}
Image distance is shown as a function of source distance.
The bar on the vertical axis shows the distance of
the retina from the lens center.
A lens power of 60 diopters brings distant objects into focus,
but not nearby objects;
to bring nearby objects into focus
the power of the lens must increase.
The depth of field, namely the distance
over which objects will continue to be in reasonable focus,
can be estimated from the slope of the curve.
}
\label{f1:accommodation}
\end{figure}
The optical {\em power} of a lens is a measure
of how strongly the lens bends the incoming rays.
Since a short focal length lens bends the incident ray more than
a long focal length lens, the
optical power is the inversely related to focal length.
The optical power is defined as the reciprocal of the focal
length measured in meters and
is specified in units of {\em diopters}.
When we view far away objects,
the distance from the middle of the
cornea and the flexible lens to the retina is 0.017m.
Hence, the optical power of the human eye is $1/0.017 = 58.8$,
or roughly 60 diopters.

From the optical power of the eye ($1/f$) and
the lensmaker's equation, we can calculate
the image distance of a source at distance.
For example, the top curve in Figure~\ref{f1:accommodation} shows the
relationship between image distance $(d_i)$
and source distance $(d_s)$ for a 60 diopter lens.
Sources beyond 1.0m
are imaged at essentially the same distance behind the optics.
Sources closer than 1.0m are imaged at a longer
distance, so that the retinal image is blurred.

To bring nearby sources into focus on the retina,
muscles attached to the
lens change its shape and thus change the power of the lens.
The bottom two curves in Figure \ref{f1:accommodation} illustrate
that sources closer than 1.0m can be focused onto the retina
by increasing the power of the lens.
The process of adjusting the focal length of the lens
is called {\em accommodation}.
You can see the effect of accommodation by first focusing on your
finger placed near your noise and noticing that objects
in the distance appear blurred.
Then, while leaving your finger in place,
focus on the distant objects.
You will notice that your finger now appears blurred.

\subsection*{Pinhole Optics and Diffraction}
The only way to remove lens imperfections completely
is to remove the lens.
It is possible to focus images without any lens at all
by using {\em pinhole} optics, as illustrated
in Figure \ref{f1:pinhole}.
\begin{figure}
\centerline {
\psfig{figure=../02imgfor/fig/pinhole.ps,clip=,height=3.0in}
}
\caption[Pinhole Optics]{ 
{\em Pinhole optics.}
Using ray-tracing, we see that only a small pencil of
rays passes through a pinhole.
(a)  If we widen the pinhole, light from the source spread across
the image, making it blurry.
(b)  If we narrow the pinhole,
only a small amount of light is let in.
The image is sharp;  the sharpness is limited by diffraction.
}
\label{f1:pinhole}
\end{figure}
A pinhole serves as a useful focusing element
because only the rays passing within a
narrow angle are used to form the image.
As the pinhole is made smaller,
the angular deviation is reduced.
Reducing the size of the pinhole
serves to reduce the amount of blur due to the
deviation amongst the rays.
Another advantage of using pinhole optics is that no matter
how distant the source point is from the pinhole,
the source is rendered in sharp focus.
Since the focusing is due to selecting out a thin pencil
of rays, the distance of the point from the pinhole
is irrelevant and accommodation is unnecessary.

But the pinhole design has two disadvantages.
First, as the pinhole aperture is reduced, less and less
of the light emitted from the source is used to
form the image.
The reduction of signal has
many disadvantages for sensitivity
and acuity.

A second fundamental limit to the pinhole design
is a physical phenomenon.
When light passes through a small aperture,
or near the edge of an aperture,
the rays do not travel in a single straight line.
Instead, the light from a single ray is scattered into many
directions and produces a blurry image.
The dispersion of light rays that pass by an edge or
narrow aperture is called {\em diffraction}.
Diffraction scatters the rays coming from a small
source across the retinal image and therefore
serves to defocus the image.
The effect of diffraction when we take an
image using pinhole optics is shown 
in Figure~\ref{f1:filament}.
\begin{figure}
\centerline{
  \psfig{figure=../02imgfor/fig/filament.ps,clip= ,height=2.5in}
}
\caption[Diffraction limited pinhole image]{
{\em Diffraction limits the quality of pinhole optics.}
The three images of a bulb filament were
imaged using pinholes with decreasing size.
(a) When the pinhole is relatively large, the image rays are not properly
converged and the image is blurred.
(b) Reducing the pinhole improves the focus.
(c) Reducing the pinhole further worsens the focus
due to diffraction.
}
\label{f1:filament}
\end{figure}

Diffraction can be explained in two different ways.
First, diffraction can be explained
by thinking of light as a wave phenomenon.
A wave exiting from a small aperture expands in all
directions;
a pair of coherent waves from adjacent apertures create an
interference pattern.
Second diffraction can be understood in terms of quantum mechanics;
indeed, the explanation of diffraction is one of the
important achievements of quantum mechanics.
Quantum mechanics supposes that there are limits
to how well we may know both the position and direction
of travel of a photon of light.
The more we know about a photon's position, the less
we can know about its direction.
If we know that a photon has passed through a small aperture,
then we know something about the photon's position
and we must pay a price in terms of
our uncertainty concerning its direction of travel.
As the aperture becomes smaller, our certainty concerning
the position of the photon becomes greater;
this uncertainty takes the form of the scattering of the
direction of travel of the photons as they pass through the aperture.
For very small apertures, for which our position certainty is high,
the photon's direction of travel is very broad producing a
very blurry image.

There is a close relationship between
the uncertainty in the direction of travel
and the shape of the aperture (see Figure~\ref{f1:diffractionPatterns}).
In all cases, however,
when the aperture is relatively large, 
our knowledge of the spatial position
of the photons is insignificant and diffraction does not
contribute to defocus.
As the pupil size decreases, and we know more about
the position of the photons, the diffraction pattern
becomes broader and spoils the focus.

\begin{figure}
\centerline{
\psfig{figure=../02imgfor/fig/diffraction.ps,clip=,height=2.0in}
}
\caption[Diffraction]{
{\em Diffraction pattern caused by a circular aperture.}
(a) The image of a diffraction pattern measured through
a circular aperture.
(b) A graph of the cross-sectional intensity of the
diffraction pattern.
(After Goodman, 1968).
% Figures 4-5, 4-4 4-3, p. 64-66.  Introduction to Fourier Optics
% McGraw-Hill.
%!!!!N.B.  The image should look circular, not elliptical.!!!!
}
\label{f1:diffractionPatterns}
\end{figure}
In the human eye diffraction occurs because light
must pass through the circular aperture defined by the pupil.
When the ambient light intensity is high,
the pupil may become as small
$2$ mm in diameter.
For a pupil opening this small, 
the optical blurring in the human eye
is due only to the small region of the cornea
and lens near the center of our visual field.
With this small an opening of the pupil,
the quality of the cornea and lens is rather good
and the main source of image blue is diffraction.
At low light intensities,
the pupil diameter is as large as 8~mm.
When the pupil is open quite wide, the distortion
due to cornea and lens imperfections is large
compared to the defocus due to diffraction.

One way to evaluate the quality of the optics
is to compare the blurring of the eye to
the blurring from diffraction alone.
The dashed lines in Figure \ref{f1:cg.linespread}
plot the blurring expected from diffraction for
different pupil widths.
Notice that when the pupil is 2.4~mm,
the observed linespread is about equal to the amount expected
by diffraction alone; the lens causes no further distortion.
As the pupil opens,
the observed linespread is worse than 
the blurring expected by diffraction alone.
For these pupil sizes the defocus
is due mainly to imperfections in the optics\footnote{
Helmholtz calculated that this was so
long before any precise measurements of the optical
quality of the eye were possible.
He wrote,
\begin{quote}
The limit of the visual capacity of the eye as imposed
by diffraction, as far as it can be calculated, is attained
by the visual acuity of the normal eye with a pupil of the
size corresponding to a good illumination.
% From Helmholtz, Phys. Optics I, page 442
(Helmholtz, 1909, p. 442)
\end{quote}
}.

\subsection*{The Pointspread Function and Astigmatism}
Most images, of course, are not composed of weighted sums of lines.
The set of images that can be formed from sums of lines oriented
in the same direction are all
one-dimensional patterns.
To create more complex images, we must either
use lines with different orientations or use a different
fundamental stimulus: the point.

Any two-dimensional image can be described
as the sum of a set of points.
If the system we are studying is linear and
shift-invariant, we can use the response to a point
and the principle of superposition
to predict the response of a system to
any two-dimensional image.
The measured response to a point input is
called the {\em pointspread} function.
A pointspread function and the superposition of two nearby
pointspreads are illustrated in Figure \ref{f1:pointspread}.
\begin{figure}
\centerline{
\psfig{figure=../02imgfor/fig/pointspread.ps,clip=,height=2.5in}
}
\caption[Pointspread Function]{
{\em A pointspread function}
(a) and the sum of two pointspreads (b).
The pointspread function is the image created
by a source consisting of a small point of light.
When the optics shift-invariant,
the image to any stimulus
can be predicted from the pointspread function.
}
\label{f1:pointspread}
\end{figure}

Since lines can be formed by adding together many different points,
we can compute the system's linespread function from the pointspread.
In general,
we cannot deduce the pointspread function from the linespread
because there is no way to add a set of lines,
all oriented in the same direction, to form a point.
If it is know that a pointspread function is circularly symmetric,
however, a unique pointspread function
can be deduced from the linespread function.
The calculation is described in the beginning of
Goodman (1968) and in Yellott, Wandell and Cornsweet (1981).
\nocite{Goodman'sBook,YellottWandellCornsweet}

\begin{figure}
\centerline{
\psfig{figure=../02imgfor/fig/astigmatism.ps,clip=,height=3.0in}
}
\caption[Astigmatism]{
{\em Astigmatism} implies an asymmetric pointspread function.
The pointspread shown here is narrow in one direction
and wide in another.
The spatial resolution of an astigmatic
system is better in the narrow direction 
than the wide direction.
}
\label{f1:astigmatism}
\end{figure}
When the pointspread functions is not circularly symmetric,
measurements of the linespread function
will vary with the orientation of the test line.
It may be possible to adjust the accommodation of this
type of system so that any single orientation is in good focus,
but it will be impossible to bring all orientations into
good focus at the same time.
For the human eye, astigmatism can usually be modeled
by describing the defocus as being derived from
the contributions of two one-dimensional systems at
right angles to one another.
The defocus in intermediate angles can be
predicted from the defocus of these two systems.
% Ask Williams for a reference on this point.

\subsection*{Chromatic Aberration}
The light incident at the eye is usually a mixture
of different wavelengths.
When we measure the system response, there is no guarantee
that the linespread or pointspread function we measure with
different wavelengths will be the same.
Indeed, for most biological eyes the
pointspread function is very different as we measure
using different wavelengths of light.
When the pointspread function of different wavelengths
of light is quite different, then the lens is said to
exhibit {\em chromatic aberration}.

\begin{figure}
\centerline{
\psfig{figure=../02imgfor/fig/c.aberration.ps,clip=,height=3.0in}
}
\caption[Chromatic Aberration]{ 
{\em Chromatic aberration of the human eye.}
(a) The data points
are from Wald and Griffin (1947), and Bedford and Wyszecki (1957).
The smooth curve plots the formula used by Thibos et al. (1992),
$D(\lambda) = p -  q / (\lambda - c )$
where $\lambda$ is wavelength in micrometers,
$D(\lambda)$ is the defocus in diopters,
$p =1.7312$, $q = 0.63346$, and $c = 0.21410$.
This formula implies an in-focus wavelength of 578 nm. 
(b) The power of a thin lens is the reciprocal
of its focal length, which is the image distance
from a source at infinity.
(After Marimont and Wandell, 1993).
%  What should we do about permission?
}
\label{f1:c.aberration}
\end{figure}
When the incident light is the mixture of many different
wavelengths, say white light, then
we can see a chromatic fringe at edges.
The fringe occurs because
the different wavelength components of the white light
are focused more or less sharply.
Figure \ref{f1:c.aberration}a
plots one measure of the chromatic aberration.
The smooth curve plots the lens power, measured
in units of {\em diopters} needed to bring
each wavelength into focus along with a 578nm light.

Figure \ref{f1:c.aberration} shows the optical power of a lens
necessary to correct for the chromatic aberration of the eye.
When the various wavelengths pass through
the correcting lens, the optics will have the
same power as the eye's optics at 578nm.
The two sets of measurements
agree well with one another and are similar to what
would be expected if the eye were simply a bowl of water.
The smooth curve through the data is a curve
used by Thibos et al. (1992) to predict the data.

\begin{figure}
\centerline{
\psfig{figure=../02imgfor/fig/acOTF.ps,clip= ,height=2.5in}
}
\caption[OTF of Chromatic Aberration]{
{\em Two views of the modulation transfer function of a model eye}
at various wavelengths.
The model eye has the same chromatic aberration as
the human eye (see Figure \ref{f1:c.aberration})
and a 3.0mm pupil diameter.
The eye is in focus at 580nm;
the curve at 580nm is diffraction limited.
The retinal image has no contrast beyond
four cycles per degree at short wavelengths.
(From Marimont and Wandell, 1993).
}
\label{f1:otf.aberration}
\end{figure}
An alternative method of representing the axial
chromatic aberration
of the eye is to plot the modulation transfer function at
different wavelengths.
The two surface plots in Figure~\ref{f1:otf.aberration}
shows the modulation
transfer function at a series of wavelengths.
The plots show the same data, but seen from different points of view
so that you can see around the hill.
The calculation in the figure is based on an eye
with a pupil diameter of 3.0mm,
the same chromatic aberration as the human eye, 
and in perfect focus except for diffraction at 580nm.
\nocite{MarimontWandell}	%chromatic aberration
\nocite{ThibosAppliedOptics1992,WaldGriffin,BedfordWyszecki}

The retinal image contains very poor spatial information
at wavelengths that are far from the best plane of focus.
By accommodation, the human eye can place any wavelength
into good focus, but it is impossible to focus
all wavelengths simultaneously\footnote{
A possible method of improving the spatial resolution of
the eye to different wavelengths of light is to place
the different classes of photoreceptors in slightly
different image planes.
Ahnelt et al. (1987) and Curcio et al. (1991) have observed that
the short-wavelength photoreceptors have a slightly
different shape and length from the middle- and
long-wavelength photoreceptors.
In principle, this difference could play a role to compensate
for the chromatic aberration of the eye.
But, the difference is very
small, and it is unlikely that it
plays any significant role in correcting for axial chromatic aberration.}.
\nocite{AhneltKolbPflug,Curcio}	%Blue cone lengths




