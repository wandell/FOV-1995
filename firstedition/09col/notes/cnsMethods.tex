\section{Reasoning about Cortex and Perception} 
Scientific investigations of the relationship between cortical
responses and perception is a reltaively new scientific endeavor,
perhaps less than 100 years old.  It is not surprising, then, that
there should be some controversy and uncertainty regarding the early
hypotheses, such as those introduced by Zeki.  Much of the controversy
stems from is due to our field's inexperience in judging which
experimental measurements will prove to be a reliable source of
information and which will not.

As you read the literature and consider various experiments that
pursue the relationship between brain and experience, consider these
two basic questions.

\be
\item What do we want to know about cortical function?

\item What experimental methods can we use to establish a relationship
between cortical responses and perception?
\ee

\subsection*{What do we want to know about cortical function?} When
one discovers a new structure in the brain, it is almost impossible
to refrain from asking: what does this part of the brain do?  Once
one poses this question, the answer is naturally formulated in terms
of the localization of perceptual function.  Hypotheses concerning
the localization of function are the most common way of formulating
research programs.  Moreover, I think any fair reading of the
historical literature will show that hypotheses about what functions
are localized within the brain region serve the useful purpose of
organizing early experiments and theory.

On the other hand, in those portions of the visual pathways where our
understanding is relatively mature, localization is rarely an
important issue.  We know that the retina is involved in visual
function, and we know that some features of the retinal encoding are
important for acuity, adaptation, wavelength encoding, and so forth.
Our grasp of retinal function is sufficiently powerful that we no
longer frame questions about retinal function as a problem of
localization.  Instead, we pose problems in terms of the flow of
information; we try to understand how the retinal information is
represented and transformed.

For example, we know that information about the stimulus wavelength is
represented by the relative absorption rates of the three cone
photopigments.  The information is not localized in any simple
anatomical sense: no single neuron contains all the necessary
information, nor are the neurons that represent wavelength information
grouped together.  Perhaps, one might argue that acuity is localized
since acuity is greatest in the fovea.  Even so, acuity depends on
image formation, proper spacing of the photoreceptors, and appropriate
representation of the photoreceptors on the optic tract.  Without all
of these others components in place, the observer will not have good
visual acuity.  The important questions about visual acuity are
questions about the nature of the information and how the information
is encoded and transmitted.  That the fovea is the region of highest
acuity is important, but not a solution to the question of how we
resolve fine detail.

The most important questions about vision are those that Helmholtz
posed: What are the principles that govern how the visual pathways
make inferences from the visual image?  How do we use image
information to compute these perceptual inferences?  We seek to
understand these principles of behavior and neural representations
with the same precision as we understand color-matching and the cone
photopigments.  We begin with spatial localization of brain function
so that we can decide where to begin our work, not how to end it.

\subsection*{Experimental Methods}
Now, we turn to the second question: what experimental methods are
reliable tools for exploring the relationship between cortical
responses and perception?  I will review and critique the principal
methods that are available to us at present.  I will describe a few
specific examples that illustrate how these results have been used
to study color appearance.

Until recently, it has been impossible to make spatially localized
measurements of neural activity in the human brain.  The vast
majority of our knowledge about the representation of information
within the human brain comes from changes in behavior resulting from
localized brain lesions due to accidents, strokes, and tumors.
Interpreting the results of brain lesions often relies on a
conceptual tool called {\em task dissociation}.  Suppose one patient
performs task A, but fails to perform task B.  We say that task A is
dissociated from task B.  We don't know, of course, whether the
inability to perform task B implies that task A also cannot be
performed.  Thus, if we find a second patient performs task B, but
fails task A, we have learned something new.  We call the pair of
observations a {\em double dissociation}.

Task dissociations suggest that the neural mechanisms required to
perform the two tasks are differentially affected by damage within the
visual pathways.  Hence, the brain mechanisms responsible for
mediating the two tasks are distinct, and they may be localized within
different positions within the brain.

As an example, consider the dissociation between color and acuity.
Individuals with poor visual acuity may still have fine color
discrimination.  Conversely, individuals with poor color vision can
have excellent visual acuity.  This double dissociation suggests that
the neural mechanisms mediating color and acuity are different.

How well does the logic of dissociation serve us in this case?  Often,
poor color discrimination can be explained by the absence of one of
the three types of cone photopigments.  Two percent of the male
population are {\em dichromats}, individuals who require only two
primaries to obtain satisfactory matches.  Most dichromats are missing
one of the cone photopigments.  Dichromats can have excellent visual
acuity.

Often, poor visual acuity is due to imperfections in the image
formation process\footnote{ There are other cases of the loss of
vision in an eye without any optical defects.  Visual dysfunction
without a known optical cause is called {\em amblyopia}.}.  The cornea
and lens produce a blurry image that limits visual acuity.  A person
has poor optics can still have excellent color vision.

It seems, then, that there is some value in the dissociation logic.
The lens and the visual photopigments are substantially different
entities; there is not much chance in confusing them.  In this sense,
the double dissociation between acuity and color vision is consistent
with spatial localization of function.

On the other hand, it is not correct to say that the visual
photopigments play no role in visual acuity.  A good supply and
arrangement of photopigments are essential for visual acuity.
Individuals missing one of the photopigments are blind to spatial
patterns formed using certain wavelength combinations, so that very
precise measurements would show that the tasks are never completely
dissociated.  And, of course, an individual missing all of the
photopigments is blind altogether.  Hence, it is not precisely true to
say that the mechanisms of color vision differ from the mechanisms of
acuity.

Nor is it precisely correct to say that optics of the eye play no role
in color vision.  We know that the chromatic aberration of the lens
is an important feature of the visual encoding that has a major
influence on how we experience color appearance.  The mechanisms of image
formation are very important to the representation of color vision in
the human visual pathways.

This example illustrates that task dissociation is a helpful, but not
subtle, tool.  When you read about clinical data, remember that function
localization and task dissociation are good starting places.  They are
not good ending places.

The lesions in clinical data are uncontrolled.  One method of
achieving better experimental control to mimic the effects of
clinical strokes is to perform animal {\em lesion experiments}.
Lesion studies also must be interpreted using the logic of task
dissociation to infer theoretical results.  In a lesion experiment,
the investigator studies the behavior of an intact animal.  Then, the
experimenter removes some portion of the brain and re-examines the
animal's behavior.  The challenge is to explain behavioral
differences, or absence of differences, before and after the lesion.

Over the last several years, methods for introducing precise lesions
within the visual pathways have progressed enormously.  These methods
have been applied to lesions in areas V4 and V5 (e.g. Heywood and
Cowey, Merigan and Maunsell, Schiller, Newsome).  For example,
P. Schiller and his colleagues studied the change in performance on a
wide variety of visual tasks in monkeys with lesions in V4, V5 and
lesions in both areas.  Lesions were introduced within a portion of V4
that represents the lower part of the visual field, while leaving
intact the remaining portion of V4.  They then compared behavior on
the same tasks when with stimuli placed in the lesioned and normal
portions of the visual field.

Schiller structured his experiments as an {\em oddity} task.  An array
of stimuli were presented on an imaginary circle.  All of the stimuli
save one were the same.  The monkey's task was to perform an eye
movement to the stimulus that differed from the others.  He reports
both the probability of correctly identifying the odd stimulus and the
latency to make the saccade.

The V4 lesions caused mild behavioral losses in a variety of tasks,
including hue, brightness, shape, and motion.  Some tasks showed no
deficit, such as stereoscopic depth.  This broad collection of
deficits is consistent with the results of other lesion studies of V4
as well (e.g. Heywood and Cowey, 1987).

Rather than a special association between V4 and color, Schiller
argues that the V4 lesion is related to the monkey's inability to
identify ``lesser'' targets from ``greater'' targets.  It was harder
for the monkey to find a small square among a collection of large
squares, a dark spot among a collection of bright spots, a low
contrast stimulus among a collection of high contrast stimuli.  When
the target was larger, brighter, or higher contrast the deficit was
mild or non-existent.  Schiller suggests that V4 may be part of the
neural circuitry involved in perceptual learning.

The behavioral studies in this and many lesion experiments are
performed well after the lesion is introduced.  We can conclude from
these studies, then, that the animal is capable of performing many
different tasks despite damage to area V4.  But, the lesioned and
intact animal may not use the same neural circuitry to perform these
tasks.  The lesioned animal's performance may be supported by
redundant circuitry within the visual pathways, or by new neural
computations that have developed in response to the lesion.  This
complicates the interpretation of lesion studies.

In the lesion method, the experimenter alters the brain and measures
the resulting change in task performance.  In the {\em subtraction
method}, the experimenter alters the task and measures the resulting
change in brain activity.

To use the subtraction method effectively, the experimenter must
design a series of tasks, each differing from one another in a unique
and significant way.  The task differences are chosen using a theory
of the neural representation of behavior.  The differences between the
tasks should be designed to uncover the workings of one or a small
number of components within the neural pathways.  For example, if one
believes that the color representation can be localized in the brain
one might create two tasks that differ only by being monochrome or
colorful.

The subtraction method is used commonly in brain imaging studies based
on positron emission tomography (PET).  In a Letter to Nature entitled
``The colour centre in the cerebral cortex of man,'' C. Lueck,
S. Zeki, K.J. Friston and others used the subtraction method to study
the representation of color in the brain.  Subjects were instructed to
look first at a collection of gray patches, and then at a collection
of colored patches of the same luminance.  The differences in the
patterns brain activity, measured indirectly through changes in the
regional cerebral blood flow, were interpreted as sites directly
involved in the perception of color (Lueck et al., 1989; Zeki et al,
1991).

Their measurements revealed larger changes in the blood flow in some
brain areas than others.  In the region of the area V1 the blood flow
only increased from 13 to 15 percent.  In another brain region, the
temporo-occipito-parietal pit, the regional blood flow increased from
three to six percent.  The largest change was in the area near the
lingual and fusiform gyrus, where the blood flow measurement increased
from 15 to 35 percent.

Recall that the lingual and fusiform gyrus is also the location
reported to be damaged in cerebral dyschromatopsia (e.g.  Verrey,
1888; Damasio et al., 1980; Zeki, 1993).  Because the changes in this
same area were large when the task changed from monochrome to color,
and because of Zeki's other arguments that monkey area V4 is a color
center, Lueck et al. argued that this area is a human color center,
analogous to monkey V4.

In a few difficult and extensive studies, experimenters have measured
simultaneously the psychophysical responses of alert behaving monkeys
and the action potentials of individual neurons.  These are {\em
correlational studies} of neural responses and behavior.  To perform
these experiments, the experimenter first places a tube in the
animal's skull.  Through this tube, the experimenter can introduce
electrodes repeatedly.  During experiments that frequently last
months or years, the animal performs various psychophysical tasks and
the experimenter measures the responses of individual or small groups
of neurons.  The simultaneous behavioral and neural measurements can
be compared to evaluate how well the animal's behavior can be
explained by the neural responses (Newsome and Movshon, 19XX; Hawken,
19XX; Tolhurst, 19XX).

Zeki (19XX) has described some observations on color appearance using a
primitive version of this method.  He created a stimulus consisting of
an array of colored papers illuminated by a variable source.  As the
illumination changed, the light reflected from the papers changed.
The color appearance of the papers, however, remains relatively
constant to the human observer and presumably to the monkey.

During the experimental measurements, Zeki moved the stimulus in order
to position different papers within the receptive field centers of V4
neurons.  He reports that responses of some V4 neurons correlate more
strongly with the stimulus surface reflectance, and thus appearance,
than with reflected light.  The responses of V1 neurons, on the other
hand, correlate better with the reflected light.  From these
observations, Zeki argued that V4 represents color appearance.

These experiments comprise only a few neurons, and no corresponding
behavioral measurement on the part of the monkey.  Still, they offer a
suggestion for how one might use the methods developed in other tasks
to analyze the representation of color appearance in the brain.

The correlational studies cannot prove causation.
W. Newsome and his colleagues have developed a powerful causal method
of relating brain activity and visual perception.  In the {\em
microstimulation} method the experimenter controls the neural activity
by introducing small amounts of current.  The stimulation changes the neural
activity while the animal animal is performing a perceptual task.  The
experimenter observes whether changing the neural response
influences the animal's responses.

The microstimulation method is very significant for two reasons.
First, in nearly every other experimental procedure, we obtain a
correlation between a neural response and the animal's behavior.
Correlations are a useful form of evidence, but weaker than
experimental manipulation.  In microstimulation experiments, the
investigator controls the activity of the neurons and thus we turn a
correlational study into a causal study.  Second, microstimulation
brings us closer to the challenge of designing visual prosthetic
devices.  By understanding the perceptual consequences of visual
stimulation, we may be able to design visual prosthetic devices that
generate predictable and controlled visual sensations.  I will review
experiments using the microstimulation method applied to motion
perception in Chapter~\ref{chapter:Motion}.

