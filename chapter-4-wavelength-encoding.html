<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>4&nbsp; Wavelength Encoding – Foundations of Vision (1995)</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./part-2-image-representation.html" rel="next">
<link href="./chapter-3-the-photoreceptor-mosaic.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./part-1-image-encoding.html">Image Encoding</a></li><li class="breadcrumb-item"><a href="./chapter-4-wavelength-encoding.html"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Wavelength Encoding</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Foundations of Vision (1995)</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">How to study vision</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Image Encoding</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./part-1-image-encoding.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction to Image Encoding</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter-2-image-formation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Image Formation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter-3-the-photoreceptor-mosaic.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">The Photoreceptor Mosaic</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter-4-wavelength-encoding.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Wavelength Encoding</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Image Representation</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./part-2-image-representation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction to Image Representation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter-5-the-retinal-representation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Retina</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter-6-the-cortical-representation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Cortical Representation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter-7-pattern-sensitivity.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Pattern Vision</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter-8-multiresolution-image-representations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Multiresolution Representations</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Image Interpretation</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./part-3-image-interpretation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction to Image Interepretation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter-9-color.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Color</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter-10-motion-and-depth.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Motion and Depth</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter-11-seeing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Seeing</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Appendix</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./appendix.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Appendix</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./numbers.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Useful numbers</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./online-teaching-resources.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Online Teaching Resources</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#wavelength-encoding-overview" id="toc-wavelength-encoding-overview" class="nav-link active" data-scroll-target="#wavelength-encoding-overview"><span class="header-section-number">4.1</span> Wavelength encoding overview</a></li>
  <li><a href="#sec-scotopic-wavelength-encoding" id="toc-sec-scotopic-wavelength-encoding" class="nav-link" data-scroll-target="#sec-scotopic-wavelength-encoding"><span class="header-section-number">4.2</span> Scotopic Wavelength Encoding</a>
  <ul class="collapse">
  <li><a href="#matching-homogeneity-and-superposition" id="toc-matching-homogeneity-and-superposition" class="nav-link" data-scroll-target="#matching-homogeneity-and-superposition">Matching: Homogeneity and superposition</a></li>
  <li><a href="#uniqueness" id="toc-uniqueness" class="nav-link" data-scroll-target="#uniqueness">Uniqueness</a></li>
  <li><a href="#the-biological-basis-of-scotopic-matching" id="toc-the-biological-basis-of-scotopic-matching" class="nav-link" data-scroll-target="#the-biological-basis-of-scotopic-matching">The Biological Basis of Scotopic Matching</a></li>
  </ul></li>
  <li><a href="#photopic-wavelength-encoding" id="toc-photopic-wavelength-encoding" class="nav-link" data-scroll-target="#photopic-wavelength-encoding"><span class="header-section-number">4.3</span> Photopic Wavelength Encoding</a>
  <ul class="collapse">
  <li><a href="#measurements-of-the-color-matching-functions" id="toc-measurements-of-the-color-matching-functions" class="nav-link" data-scroll-target="#measurements-of-the-color-matching-functions">Measurements of the Color-Matching Functions</a></li>
  <li><a href="#uniqueness-of-the-color-matching-functions" id="toc-uniqueness-of-the-color-matching-functions" class="nav-link" data-scroll-target="#uniqueness-of-the-color-matching-functions">Uniqueness of the Color-Matching Functions</a></li>
  <li><a href="#a-standard-set-of-color-matching-functions" id="toc-a-standard-set-of-color-matching-functions" class="nav-link" data-scroll-target="#a-standard-set-of-color-matching-functions">A Standard Set of Color-Matching Functions</a></li>
  <li><a href="#the-biological-basis-of-photopic-color-matching" id="toc-the-biological-basis-of-photopic-color-matching" class="nav-link" data-scroll-target="#the-biological-basis-of-photopic-color-matching">The Biological Basis of Photopic Color-matching</a></li>
  <li><a href="#measuring-cone-photocurrents" id="toc-measuring-cone-photocurrents" class="nav-link" data-scroll-target="#measuring-cone-photocurrents">Measuring Cone Photocurrents</a></li>
  <li><a href="#static-nonlinearities-photocurrents-and-photopigments" id="toc-static-nonlinearities-photocurrents-and-photopigments" class="nav-link" data-scroll-target="#static-nonlinearities-photocurrents-and-photopigments">Static Nonlinearities: Photocurrents and Photopigments</a></li>
  <li><a href="#static-nonlinearities-the-principle" id="toc-static-nonlinearities-the-principle" class="nav-link" data-scroll-target="#static-nonlinearities-the-principle">Static Nonlinearities: The principle</a></li>
  <li><a href="#cone-photopigments-and-color-matching" id="toc-cone-photopigments-and-color-matching" class="nav-link" data-scroll-target="#cone-photopigments-and-color-matching">Cone Photopigments and Color-matching</a></li>
  <li><a href="#why-this-is-a-big-deal" id="toc-why-this-is-a-big-deal" class="nav-link" data-scroll-target="#why-this-is-a-big-deal">Why this is a big deal</a></li>
  </ul></li>
  <li><a href="#color-deficiencies" id="toc-color-deficiencies" class="nav-link" data-scroll-target="#color-deficiencies"><span class="header-section-number">4.4</span> Color Deficiencies</a>
  <ul class="collapse">
  <li><a href="#small-field-dichromacy" id="toc-small-field-dichromacy" class="nav-link" data-scroll-target="#small-field-dichromacy">Small field dichromacy</a></li>
  <li><a href="#dichromatic-observers" id="toc-dichromatic-observers" class="nav-link" data-scroll-target="#dichromatic-observers">Dichromatic observers</a></li>
  <li><a href="#anomalous-observers" id="toc-anomalous-observers" class="nav-link" data-scroll-target="#anomalous-observers">Anomalous Observers</a></li>
  </ul></li>
  <li><a href="#color-appearance" id="toc-color-appearance" class="nav-link" data-scroll-target="#color-appearance"><span class="header-section-number">4.5</span> Color Appearance</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./part-1-image-encoding.html">Image Encoding</a></li><li class="breadcrumb-item"><a href="./chapter-4-wavelength-encoding.html"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Wavelength Encoding</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span id="sec-wavelength-encoding" class="quarto-section-identifier"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Wavelength Encoding</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="wavelength-encoding-overview" class="level2" data-number="4.1">
<h2 data-number="4.1" class="anchored" data-anchor-id="wavelength-encoding-overview"><span class="header-section-number">4.1</span> Wavelength encoding overview</h2>
<p>Sir Isaac Newton’s sketch in <a href="#fig-newton" class="quarto-xref">Figure&nbsp;<span>4.1</span></a> summarizes his investigations into the properties of light. In these experiments, Newton separated daylight into its fundamental components by passing it through a prism and creating a rainbow. Newton’s demonstration that light can be decomposed into rays of different wavelength is at the foundation of our understanding of light and color.</p>
<p>To perform these experiments, Newton placed a shutter containing a small hole in the window in his room at Cambridge. The light emerging from the hole in the window shutter served as a point source to illuminate his apparatus. The key elements of the apparatus are featured prominently in the center of the figure: the lens and prism. Newton’s drawing shows that when the daylight passed through the prism, it formed an image of a rainbow on his wall. With two experimental manipulations, he showed that the components of the rainbow were fundamental constituents of light. In the upper left of the sketch, we see a series of holes that Newton drilled in the wall permitting part of the rainbow to continue through to a second prism. This ray of light was cast upon a second surface, but the new image did not produce a second rainbow; rather, as Newton wrote:</p>
<blockquote class="blockquote">
<p><em>“the color of the light was never changed in the least. If any part of the red light was refracted, it remained totally of the same red color as before. No orange, no yellow, no green or blue, nor other new color was produced by that refraction.” (<span class="citation" data-cites="newton1984">Newton (<a href="references.html#ref-newton1984" role="doc-biblioref">1984</a>)</span>)</em></p>
</blockquote>
<div id="fig-newton" class="aligncenter quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-newton-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./wp-content/uploads/2012/02/newton.png" class="aligncenter img-fluid figure-img" style="width:90.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-newton-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.1: Newton’s summary drawing of his experiments with light. Using a point source of light and a prism, Newton separated sunlight into its fundamental components. By reconverging the rays, he also showed that the decomposition is reversible.
</figcaption>
</figure>
</div>
<p>From this experiment, Newton concluded that the pass through the first prism had separated the daylight into its fundamental components. No further change was observed when the ray passed through a second prism.</p>
<p>At the bottom of the sketch Newton illustrated that the decomposition is reversible: passing light through the prism does not destroy the character of the light. To show this Newton converged the rays following their passage through the prism to form a new image; he found that the color of the image same is the same as that of the source. Newton concluded that:</p>
<blockquote class="blockquote">
<p><em>“Light being transmitted through the parallel surfaces of two prisms … if it suffered any change by the refraction by one surface, it lost that impression by the contrary refraction of the other surface.”(<span class="citation" data-cites="newton1984">Newton (<a href="references.html#ref-newton1984" role="doc-biblioref">1984</a>)</span>)</em></p>
</blockquote>
<p>From the second experiment, he concluded that passage through the prism had not destroyed, but merely revealed, the character of the light.</p>
<p>We now know that Newton succeeded in decomposing the sunlight into its <em>spectral</em> components, each with its own characteristic wavelength. The prism separates the rays because the prism bends each wavelength of light by a different amount. (See the section on Snell’s law in <a href="chapter-2-image-formation.html" class="quarto-xref"><span>Chapter 2</span></a>). When we see the spectral components separately, they each have a different color appearance. Light with relatively long wavelengths appears red when viewed against a dark background. Light with relatively short wavelengths appears blue when viewed against a dark background. Shorter wavelengths of light are refracted more strongly than longer wavelengths. A spectral light, with energy only at a single wavelength, is also called a <em>monochromatic light</em>.</p>
<div id="fig-spectroradiometer" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-spectroradiometer-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./wp-content/uploads/2012/02/spectroradiometer.png" class="img-fluid figure-img" style="width:80.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-spectroradiometer-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.2: A spectroradiometer is used to measure the spectral power distribution of light. (a) A schematic design of a spectroradiometer includes a means for separating the input light into its different wavelengths and a detector for measuring the energy at each of the separate wavelengths. (b) The color names associated with the appearance of lights at a variety of wavelengths are shown (After <span class="citation" data-cites="wyszeckicolorscienceconcepts1982">Wyszecki and Stiles (<a href="references.html#ref-wyszeckicolorscienceconcepts1982" role="doc-biblioref">1982</a>)</span>).
</figcaption>
</figure>
</div>
<p>Newton’s apparatus suggests a simple device we might build to measure the amount of power a light has in each of the different wavelength bands. As illustrated on the top of <a href="#fig-spectroradiometer" class="quarto-xref">Figure&nbsp;<span>4.2</span></a>, by proper use of lenses and prisms, we can form a focused image of the spectral components in an image plane with a movable slit placed in front of a photodetecting sensor. To measure the energy at different wavelengths, we move the slit passing only some of the spectral components at each position, and thus we measure the energy of the source at different wavelengths of light. In the visible region, the wavelength of light is on the order of a few hundred billionths of a meter, or <em>nanometers</em> (nm).</p>
<p>The <em>spectral power distribution</em> of a light is the function that defines the power (Watts = Joules/sec) in the light in each wavelength band. In the modern theory of physics, the wavelength of light can be thought of in two different ways. We describe the light as if it were a continuous wave as it passes through a medium. When the light exchanges energy with some material, say by giving up its energy to be absorbed, we describe the light as if it were a discrete object called a <em>photon</em> or <em>quantum</em> of light. The amount of energy given up by the photon is predicted by the wavelength of the light.</p>
<div id="fig-superposition" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-superposition-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./wp-content/uploads/2012/02/ill.superposition.png" class="img-fluid figure-img" style="width:60.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-superposition-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.3: Principle of Superposition. The measurement of light spectral power distributions satisfies the principle of superposition. The spectral power distributions of two lights measured separately are shown in (a) and (b) and together in (c). The spectral power distribution of the mixture is the sum of the individual measurements, thus demonstrating that superposition holds true.
</figcaption>
</figure>
</div>
<p>The experimental aspect of light measurement that makes it useful and predictable is that the measurement satisfies the principle of superposition. We can demonstrate the superposition of light measurement as follows. First, measure the spectral power distributions of two lights separately. Then, mix the two lights together and measure again. The spectral power distribution of the mixture will be the sum of the first two spectral power distributions. This property of light mixture is illustrated in <a href="#fig-superposition" class="quarto-xref">Figure&nbsp;<span>4.3</span></a>. Superposition is a crucial property of light measurement because it implies that we can measure the energy of a light at each wavelength separately, and then combine the individual measurements to predict spectral power distribution when the spectral components are mixed together.</p>
<p>Suppose we wish to measure the spectral power distribution of a light source. How many wavelengths should we measure? Or, equivalently, how finely do we have to sample along the wavelength dimension? The answer to this question is important for both practical and theoretical reasons because the number of samples can be quite large. For example, to sample the visible spectrum from 400 nm to 700 nm in 1 nm steps, we need about 300 measurements. To sample in 10 nm steps, we need about 30 measurements.</p>
<p>The answer to this sampling question depends on the same set of issues as the sampling questions we addressed in <a href="chapter-3-the-photoreceptor-mosaic.html" class="quarto-xref"><span>Chapter 3</span></a> on the spatial sampling of the retinal image by the photoreceptor mosaics. If the energy in the light varies rapidly as a function of wavelength, then we may have to sample quite finely to measure accurately; if the functions vary slowly, then only a few measurements are necessary. Also, the precision of the representation requires that we know how sensitive the photopigments in the are to rapid changes in the energy as a function of wavelength.</p>
<div id="fig-spectra1" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-spectra1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./wp-content/uploads/2012/02/spectra1.png" class="img-fluid figure-img" style="width:60.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-spectra1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.4: The spectral power distribution of two important light sources are shown: blue skylight (a) and the yellow disk of the sun (b).
</figcaption>
</figure>
</div>
<p>It is difficult to make accurate generalizations about how spectral power distributions vary as a function of wavelength, but it is believed widely that for practical purposes we can approximate spectral power distributions using smooth, regular functions as shown in <a href="#fig-spectra1" class="quarto-xref">Figure&nbsp;<span>4.4</span></a>. Also, it is known that the photopigments integrate broadly across the wavelength spectrum. Consequently, international standards organizations suggest making measurements every 5 nm to achieve an excellent representation of the signal. Practical measurements often rely on measurements spaced every 10 or 20 nm. We will consider this issue much more completely when we review color appearance, in <a href="chapter-9-color.html" class="quarto-xref"><span>Chapter 9</span></a>.</p>
</section>
<section id="sec-scotopic-wavelength-encoding" class="level2" data-number="4.2">
<h2 data-number="4.2" class="anchored" data-anchor-id="sec-scotopic-wavelength-encoding"><span class="header-section-number">4.2</span> Scotopic Wavelength Encoding</h2>
<p>What information do we encode about the spectral power distribution when rods initiate vision, under <em>scotopic</em> conditions? We can answer this question by an experiment designed to measure how well people can discriminate different spectral power distributions. In the <em>scotopic matching</em> experiment, we present an observer with two lights, side by side in a <em>bipartite</em> field. One side of the field contains the <em>test</em> light; it may have any spectral power distribution whatsoever. The second side of the field contains the <em>primary</em> light; it has a fixed relative spectral power distribution and can vary only by an overall intensity factor. The observer’s task in the <em>scotopic matching experiment</em> is to adjust the primary light intensity so that the primary light appears indistinguishable from the test light. The observer can adjust only the intensity of the primary light, so when the match is achieved the spectral power distributions of the test and primary lights that match are still different.</p>
<p>Under scotopic conditions, observers can adjust the primary intensity so that the primary matches any test light. Since subjects can always make this match, we have a simple answer to our question: The rods encode nothing about the relative spectral density of a light. An observer can adjust the intensity of a primary light to match the appearance of a test light with any spectral power distribution. The relative spectral power distribution is immaterial, all that matters is the relative intensities of the two lights.</p>
<section id="matching-homogeneity-and-superposition" class="level3">
<h3 class="anchored" data-anchor-id="matching-homogeneity-and-superposition">Matching: Homogeneity and superposition</h3>
<p>We can learn more about scotopic wavelength encoding by studying the quantitative properties of the matching experiment. To characterize the matching experiment completely, we must be able to predict how a subject will adjust the primary intensity to match any test light. We treat the experiment as a transformation by identifying the spectral power distribution of the test light as the input and the intensity of the primary light as the output. A quantitative description of the experiment tells us how to map the input to the output.</p>
<p>Naturally, we first ask whether we can characterize the matching experiment transformation using linear systems methods. Denote the spectral power distribution of the test and primary lights using the vectors <span class="math inline">\(\mathbf{t}\)</span> and <span class="math inline">\(\mathbf{p}\)</span> respectively. The <span class="math inline">\(n_{\lambda}\)</span> entries of these vectors describe the power at each of the <span class="math inline">\(n_{\lambda}\)</span> sample wavelengths. To test linearity, we evaluate whether the scotopic matching experiment satisfies the linear systems properties of homogeneity and superposition. We can evaluate these properties from the following experimental tests:</p>
<ul>
<li>(Homogeneity) If <span class="math inline">\(\mathbf{t}\)</span> matches <span class="math inline">\(e \mathbf{p}\)</span>, will <span class="math inline">\(a \mathbf{t}\)</span> match <span class="math inline">\(a (e \mathbf{p})\)</span>?</li>
<li>(Superposition) If <span class="math inline">\(\mathbf{t}\)</span> matches <span class="math inline">\(e \mathbf{p}'\)</span>, and <span class="math inline">\({\mathbf{t}'}\)</span> matches <span class="math inline">\({e'} \mathbf{p}'\)</span>, will <span class="math inline">\(\mathbf{t} + \mathbf{t}'\)</span> match <span class="math inline">\(( e \mathbf{p} ) + ( e' \mathbf{p} )\)</span>?</li>
</ul>
<p>An hypothetical test of homogeneity is shown in <a href="#fig-scotopic" class="quarto-xref">Figure&nbsp;<span>4.5</span></a>. The separate panels show the intensity of the test light on the horizontal axis and the intensity of the matching primary light on the vertical axis. Each panel plots the results using spectral test lights at a series of wavelengths and a 510 nm primary light. In the scotopic matching experiment the data will fall on a straight line, consistent with the prediction from homogeneity. The slope of the line defines the relative scotopic sensitivity to the test and the primary lights. For example, in panel (c) the hypothetical results from an experiment with a 580 nm test light are shown. The slope of the line shows that we need <span class="math inline">\(8.3\)</span> units of energy at 580 nm to have the same effect as one unit of energy at 510 nm. Hence, the light at 510 nm is <span class="math inline">\(8.3\)</span> times more effective, per unit energy, than the light at 580 nm.</p>
<div id="fig-scotopic" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-scotopic-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./wp-content/uploads/2012/02/scotopic.png" class="img-fluid figure-img" style="width:80.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-scotopic-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.5: Hypothetical scotopic matching experiment. The horizontal scale measures the intensity of a monochromatic test light and the vertical scale measures the intensity a matching 510 nm primary light. Since the scotopic matching experiment satisfies homogeneity, the data will fall along a straight line. The slope of the line defines the relative scotopic sensitivity to each test wavelength.
</figcaption>
</figure>
</div>
<p>Because the scotopic matching experiment is linear, there must be a system matrix, <span class="math inline">\(\mathbf{R}\)</span> that maps the input (<span class="math inline">\(\mathbf{t}\)</span>, the test spectral power distribution), to the output (<span class="math inline">\(e\)</span>, the primary light intensity). The system matrix, call it <span class="math inline">\(\mathbf{R}\)</span>, must have one row and <span class="math inline">\(n_{\lambda}\)</span> columns. The test light, system matrix, and primary intensity are related by the product, <span class="math inline">\(e = \mathbf{R} \mathbf{t}\)</span>.</p>
<div id="fig-scotopic-tableau" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-scotopic-tableau-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./wp-content/uploads/2012/02/Scotopic-Tableau.png" class="img-fluid figure-img" style="width:50.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-scotopic-tableau-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.6: Matrix tableau of the scotopic matching experiment. The primary light intensity, e, equals the product of the <span class="math inline">\(1 \times n_{\lambda}\)</span> scotopic matching system matrix and the <span class="math inline">\(n_{\lambda} \times 1\)</span> vector representing the test light spectral power distribution.
</figcaption>
</figure>
</div>
<p>We can relate the measurements in the scotopic matching experiment to the entries of the system matrix as follows. Write the matrix product <span class="math inline">\(\mathbf{R} \mathbf{t}\)</span> as a summation over the sample wavelengths,</p>
<p><span id="eq-scotopic-sum"><span class="math display">\[
e = \sum_{i=1}^{i=n_{\lambda}} R_{i} \mathbf{t}_{i}
\tag{4.1}\]</span></span></p>
<p>Suppose we use a monochromatic test light of unit intensity, that is, an input <span class="math inline">\(\mathbf{t}\)</span> that has only a single non-zero wavelength, <span class="math inline">\((0,0,...,0,1,0,...0)^{T}\)</span>. Then <a href="#eq-scotopic-sum" class="quarto-xref">Equation&nbsp;<span>4.1</span></a> becomes simply <span class="math inline">\(e = R_{i} \mathbf{t}_{i}\)</span>. This shows that the slope of the line relating the monochromatic test intensity, <span class="math inline">\(\mathbf{t}_{i}\)</span>, to the primary intensity, <span class="math inline">\(e\)</span>, is the system matrix entry, <span class="math inline">\(R_{i}\)</span>. Hence, we can estimate the system matrix from the slopes of the experimental lines we measure in the test of homogeneity shown in <a href="#fig-scotopic" class="quarto-xref">Figure&nbsp;<span>4.5</span></a>.</p>
<div id="fig-scotopic-sens" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-scotopic-sens-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./wp-content/uploads/2012/02/scot.sens_.png" class="img-fluid figure-img" style="width:60.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-scotopic-sens-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.7: The scotopic spectral sensitivity function defines the human wavelength sensitivity under scotopic viewing conditions. The curve is a plot of the entries of the scotopic system matrix.
</figcaption>
</figure>
</div>
<p><a href="#fig-scotopic-sens" class="quarto-xref">Figure&nbsp;<span>4.7</span></a> is a graphical method of representing the system matrix of the scotopic matching experiment. The curve shows the entries of <span class="math inline">\(\mathbf{R}\)</span> as a function of wavelength, interpolated from experimental measurements at many sample wavelengths. The curve is called the <em>scotopic sensitivity function</em>.</p>
<p>Once we measure the system matrix, <span class="math inline">\(\mathbf{R}\)</span>, we can predict whether any pair of lights will match under scotopic conditions. The matrix tableau shows how we use the system matrix to predict the intensity of a primary light needed to match a test light. Suppose we have two test lights, <span class="math inline">\(\mathbf{t}\)</span> and <span class="math inline">\(\mathbf{t} '\)</span>. Two lights will match when they are matched by the same intensity of the primary light. So, these two lights will match when <span class="math inline">\(\mathbf{R} \mathbf{t} = \mathbf{R} \mathbf{t} '\)</span>.</p>
</section>
<section id="uniqueness" class="level3">
<h3 class="anchored" data-anchor-id="uniqueness">Uniqueness</h3>
<p>The hypothetical experiment illustrated in <a href="#fig-scotopic-tableau" class="quarto-xref">Figure&nbsp;<span>4.6</span></a> assumed a 510 nm primary light. Suppose that we perform the scotopic matching experiment using a different primary light. How will this effect the system matrix, <span class="math inline">\(\mathbf{R}\)</span>?</p>
<p>We can answer this question by a thought experiment. Call the second primary light <span class="math inline">\(\mathbf{p}'\)</span>. We can set a match between the new primary light, <span class="math inline">\(\mathbf{p}'\)</span>, and the first primary light <span class="math inline">\(\mathbf{p}\)</span>. We will find that there is some scalar, <span class="math inline">\(k\)</span>, such that <span class="math inline">\(k \mathbf{p}'\)</span> matches <span class="math inline">\(\mathbf{p}\)</span>, and we expect that whenever <span class="math inline">\(a \mathbf{p}\)</span> matches a test light, <span class="math inline">\(\mathbf{t}\)</span>, then <span class="math inline">\(a (k \mathbf{p}')\)</span> will match <span class="math inline">\(\mathbf{t}\)</span>. In particular, since <span class="math inline">\(R_{i} \mathbf{p}\)</span> matches the <span class="math inline">\(i^{th}\)</span> monochromatic test light, we expect that <span class="math inline">\(R_{i} k \mathbf{p}'\)</span> will match the <span class="math inline">\(i^{th}\)</span> monochromatic test light as well. It follows that the entries of the new system matrix will be <span class="math inline">\(k R_{i}\)</span>, equal to the original except for a constant scale factor, <span class="math inline">\(k\)</span>. Hence, the new system matrix will be <span class="math inline">\(k \mathbf{R}\)</span>, and we say that the estimate of <span class="math inline">\(\mathbf{R}\)</span> is unique up to an unknown scale factor.</p>
</section>
<section id="the-biological-basis-of-scotopic-matching" class="level3">
<h3 class="anchored" data-anchor-id="the-biological-basis-of-scotopic-matching">The Biological Basis of Scotopic Matching</h3>
<p>Color Plate 1 is a photograph of the photopigment contained in the rod outer segments. In part (a) of the figure the photopigment is photographed in the eye of an alligator. Because the back of the alligator’s eye contains a white reflective surface, called the <em>tapetum</em>, it is possible to see the color of the rod photopigment. Cats too have a white tapetum, which is why cats eyes appear to glow so brightly when they catch the beam of a car’s headlights. The alligator shown in the picture had been kept in a dark closet for 24 hours so that the photopigment would be fully regenerated and easy to photograph. The closet was opened briefly, a flash picture taken, and then I suppose the door was shut again. Whew. </p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./wp-content/uploads/2012/02/Alligator.png" class="img-fluid figure-img" style="width:60.0%"></p>
<figcaption><strong>Color Plate 1.</strong> The scotopic matching experiment is remarkable in its simplicity. We can understand the biological basis of the experimental matches by studying the properties of the rod photopigment, rhodopsin.</figcaption>
</figure>
</div>
<p>Rod photopigment is present in much higher density than any of the cone photopigments. Thus, researchers have been able to isolate and extract the rod photopigment for fifty years, whereas the cone photopigments have only become available recently through the methods of genetic engineering (<span class="citation" data-cites="merbs1992-cones">Merbs and Nathans (<a href="references.html#ref-merbs1992-cones" role="doc-biblioref">1992</a>)</span>). Characteristically, when the rod photopigment is exposed to light, it undergoes a series of rapid changes in chemical state (<span class="citation" data-cites="hubbard-wald1951">Hubbard and Wald (<a href="references.html#ref-hubbard-wald1951" role="doc-biblioref">1951</a>)</span>; <span class="citation" data-cites="wald1958-humanrhodopsin">Wald and Brown (<a href="references.html#ref-wald1958-humanrhodopsin" role="doc-biblioref">1958</a>)</span>; <span class="citation" data-cites="wald1968-molvisualexcit">Wald (<a href="references.html#ref-wald1968-molvisualexcit" role="doc-biblioref">1968</a>)</span>). Whenever a quantum of light is absorbed by the rhodopsin photopigment, it undergoes a specific sequence of events resulting in the decomposition of the rhodopsin molecule into opsin and vitamin A. Color Plate 1 (b) shows the same alligator after its eye has been exposed to light. The rhodopsin is been broken into two parts and the resulting products are clear, rather than purple. In this state, the white tapetum of the eye is evident. It is the wavelength selectivity of the rhodopsin photopigment that provides the biological basis of scotopic matching. The relationship between the behavioral experiment and the properties of the rod photopigment is based on an important property called <em>univariance</em>.</p>
<p>W. Rushton emphasized that when a photopigment molecule absorbs light, the effect upon the photopigment is the same no matter what the wavelength of the absorbed light might be. Thus, even though quanta at 400 nm possess more energy than quanta at 700 nm, the sequence of rhodopsin reactions to absorption of a 400 nm quantum is the same as the sequence of reactions to a 700 nm quantum. Rushton used the word <em>univariance</em> for this principle to remind us that a single photopigment makes only a single-variable response to the incoming light. The photopigment maps all spectral lights into a single-variable output, the <em>rate of absorptions</em>. The response of a single photopigment does not encode any information about the relative spectral composition of the light. This explains why we cannot discriminate between lights with different spectral power distributions under scotopic viewing conditions (<span class="citation" data-cites="rushton1965-rodsensitivity">Rushton (<a href="references.html#ref-rushton1965-rodsensitivity" role="doc-biblioref">1965</a>)</span>; <span class="citation" data-cites="naka-rushton1966">Naka and Rushton (<a href="references.html#ref-naka-rushton1966" role="doc-biblioref">1966</a>)</span>).</p>
<div id="fig-self-screening" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-self-screening-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./wp-content/uploads/2012/02/self.screening1.png" class="img-fluid figure-img" style="width:70.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-self-screening-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.8: An apparatus to measure the spectral absorption of a photopigment. Using the monochromator, one can select light at one wavelength from the light source. To estimate the fraction of photons absorbed by the photopigment at that wavelength, we divide the number of photons detected through the glass and photopigment by the number detected after passing through the glass alone.
</figcaption>
</figure>
</div>
<p>Univariance does not mean, however, that the photopigment responds equally well to all spectral lights. The photopigment is much more likely to absorb some wavelengths of light than others. Univariance asserts that once absorbed, however, all quanta have same visual effect.</p>
<p>We can measure the probability of absorption using the experimental apparatus shown in <a href="#fig-self-screening" class="quarto-xref">Figure&nbsp;<span>4.8</span></a>. We place a thin layer of photopigment on a clear plate of glass. We create a monochromatic light by passing the light from an ordinary source through a <em>monochromator</em>. The monochromator can be constructed using prisms or diffraction gratings to separate the incident light into its separate wavelengths, much as in Newton’s original experiments. We measure the amount of monochromatic light passed through the photopigment and the glass plate by means of a photodetector at the rear of the apparatus. We then move the glass plate upwards, to remove the photopigment from the light path, and measure again. The difference in the photodetector signal measured in these two conditions is proportional to the amount of light absorbed by the photopigment.</p>
<div id="fig-scotopic1" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-scotopic1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./wp-content/uploads/2012/02/scotopic1.png" class="img-fluid figure-img" style="width:70.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-scotopic1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.9: Rhodopsin absorptions at different wavelengths. The number of absorptions in a thin layer of photopigment are proportional to the intensity of the input light and thus satisfy the principle of homogeneity. The slope of the linear relationship between the light intensity and the number of absorptions describes the fraction of photon absorptions. The slope varies with the wavelength of the test light, thus defining the photopigment wavelength sensitivity.
</figcaption>
</figure>
</div>
<p>If only a thin layer of photopigment is present, the experimental measurements of the absorptions will satisfy homogeneity and superposition. To test homogeneity, we increase the intensity of the test light. We will find that the number of absorptions will increase proportionately over a significant range. To test superposition, we measure the photopigment absorptions to a test light <span class="math inline">\(\mathbf{t}\)</span> to be <span class="math inline">\(a\)</span>, and the number of absorptions to a second light <span class="math inline">\(\mathbf{t}'\)</span> to be <span class="math inline">\(a'\)</span>. When we superimpose the two input lights, we will measure <span class="math inline">\(a + a'\)</span> absorptions. Since the measurement process is linear, we can estimate the system matrix of this absorption process, <span class="math inline">\(\mathbf{A}\)</span>, just as we measured the system matrix of the scotopic matching experiment, <span class="math inline">\(\mathbf{R}\)</span>.</p>
<div id="fig-rhodopsin-sens" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-rhodopsin-sens-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./wp-content/uploads/2012/02/rhodopsin.sens_.png" class="img-fluid figure-img" style="width:60.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-rhodopsin-sens-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.10: Comparisons of scotopic matching and rhodopsin wavelength sensitivity. The filled circles show human rhodopsin absorption measured as in <a href="#fig-scotopic1" class="quarto-xref">Figure&nbsp;<span>4.9</span></a>. The open circles show human scotopic sensitivity, corrected for light loss at the lens and optical media. (Source: <span class="citation" data-cites="wald1958-humanrhodopsin">Wald and Brown (<a href="references.html#ref-wald1958-humanrhodopsin" role="doc-biblioref">1958</a>)</span>)
</figcaption>
</figure>
</div>
<p>We can predict the matches in the scotopic matching experiment from the absorptions of the rhodopsin photopigment. A test and primary light match in the scotopic matching experiment when the two lights create the same number of absorptions in the rhodopsin photopigment. We can demonstrate this by comparing the system matrices of the scotopic matching experiment and the rhodopsin absorption experiment. After we correct for the effects of the wavelength sensitive elements of the eye, mainly the lens, we can plot the system matrices of the scotopic matching experiment <span class="math inline">\(\mathbf{R}\)</span>, and the rhodopsin absorption experiment, <span class="math inline">\(\mathbf{A}\)</span>, on the same graph. <span class="citation" data-cites="wald1958-humanrhodopsin">Wald and Brown (<a href="references.html#ref-wald1958-humanrhodopsin" role="doc-biblioref">1958</a>)</span> made this comparison in the graph shown in <a href="#fig-rhodopsin-sens" class="quarto-xref">Figure&nbsp;<span>4.10</span></a>. The filled circles in the graph plot the measurements of the system matrix from the rhodopsin absorption experiment, <span class="math inline">\(\mathbf{A}\)</span>. The completely open circles plot estimates of the entries of <span class="math inline">\(\mathbf{R}\)</span> after correcting for the fact that the lens absorbs a significant amount of light in the short-wavelength part of the spectrum.</p>
<p>The agreement between the measurements of the rhodopsin photopigment and the scotopic matching experiment confirm a simple model of the observer’s behavior. Under scotopic viewing conditions the observer’s perception of the two halves of the bipartite field depends on a signal initiated by the rod photopigment absorptions. The two sides of the field appear identical when the rhodopsin absorption rates on the two sides of the bipartite field are equal. During the experiment, then, the observer adjusts the intensity of the matching light to equalize the rod absorption rates on the two sides of the bipartite field. Since the absorption of the light is a linear process, the observer’s behavior is linear, too.</p>
<p>The precise quantitative match between the scotopic matches and the rod photopigment make a very strong connection between performance and biological encoding of the light. This type of precise quantitative relationship between behavior and the biological encoding of light serves as a good standard to use when we consider the relationship between behavior and biology in other conditions.</p>
</section>
</section>
<section id="photopic-wavelength-encoding" class="level2" data-number="4.3">
<h2 data-number="4.3" class="anchored" data-anchor-id="photopic-wavelength-encoding"><span class="header-section-number">4.3</span> Photopic Wavelength Encoding</h2>
<p>When the cones initiate vision, under photopic conditions, we do encode some information about the relative spectral power distribution of the incident light. Changes in the relative spectral power distributions result in changes of the color appearance of the light. Several of the important properties of color appearance can be traced to the way cone photoreceptors encode the relative spectral power distribution of light<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>.</p>
<div id="fig-color-matching" class="aligncenter quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-color-matching-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./wp-content/uploads/2012/02/colorMatching.png" class="aligncenter img-fluid figure-img" style="width:60.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-color-matching-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.11: The color-matching experiment. The observer views a bipartite field and adjusts the intensities of the three primary lights to match the appearance of the test light. (a) A side-view of the experimental apparatus. (b) The appearance of the stimuli to the observer. (After <span class="citation" data-cites="judd-wyszecki1975">Judd and Wyszecki (<a href="references.html#ref-judd-wyszecki1975" role="doc-biblioref">1975</a>)</span>)
</figcaption>
</figure>
</div>
<p>We will relate the human ability to discriminate lights to the properties of the cones just as we did with the rods. First, we will review the matching experiments that characterize how well people can discriminate between lights with spectral power distributions. When we measure under photopic conditions, the experiment is called the <em>color-matching</em> experiment. The color-matching experiment is the foundation of color science and of direct significance to many color applications (see the Appendix). Second, we will relate the properties of the color-matching experiment to the properties of the cone photopigments. The analysis of photopic wavelength encoding parallels the analysis of scotopic wavelength encoding. The main differences are that (a) we must keep track of the photopigment absorptions in three cone photopigments rather than the single rod photopigment, and (b) until quite recently the cone photopigments were not present in sufficient quantity to define their properties with any certainty (<span class="citation" data-cites="merbs1992-cones">Merbs and Nathans (<a href="references.html#ref-merbs1992-cones" role="doc-biblioref">1992</a>)</span>). Hence, the problem of relating color-matching and the cone photopigments was solved using other indirect biological measurements. We can learn a great deal from studying the logic of these methods.</p>
<p><a href="#fig-color-matching" class="quarto-xref">Figure&nbsp;<span>4.11</span></a> shows a simple apparatus that can be used to perform the color-matching experiment. The observer views a bipartite visual field with the test light on one side. The test light may have any spectral power distribution. The second half of the bipartite field contains a mixture of <em>three</em> primary lights. Throughout the experiment, the relative spectral power distribution of each primary light is constant; only the absolute level of the primary lights can be adjusted. The observer’s task is to adjust the intensities of the three primary lights so that the two sides of the bipartite field appear identical.</p>
<div id="fig-tv-metamers" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-tv-metamers-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./wp-content/uploads/2012/02/tvMetamers.png" class="img-fluid figure-img" style="width:60.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-tv-metamers-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.12: Metameric lights. Two lights with these spectral power distributions appear identical to most observers and are called metamers. The curve in part (a) is an approximation to the spectral power distribution of the sun. The curve in part (b) is the spectral power distribution of a light emitted from a conventional television monitor whose three phosphor intensities were set to match the light in (a) in appearance.
</figcaption>
</figure>
</div>
<p>When the observer has completed setting an appearance match, the lights on the two sides of the bipartite field are not physically the same. The test light can have any spectral power distribution, while the mixture of primaries can only have a limited number of spectral power distributions determined by the possible weighted sums of the three primary light spectral power distributions. Lights that are photopic appearance matches, but that are physically different, are called <em>metamers</em>. <a href="#fig-tv-metamers" class="quarto-xref">Figure&nbsp;<span>4.12</span></a> contains a pair of spectral power distributions that match visually but differ physically, i.e.&nbsp;a pair of metamers.</p>
<p>The metamers in <a href="#fig-tv-metamers" class="quarto-xref">Figure&nbsp;<span>4.12</span></a> illustrate that even under photopic viewing conditions we fail to discriminate between very different spectral power distributions. To understand the behavioral aspects of photopic wavelength encoding, we must try to predict which spectral power distributions we can discriminate. The first question we ask is whether we can predict performance in the photopic color-matching experiment using linear systems methods.</p>
<div id="fig-phot-superposition" class="aligncenter quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-phot-superposition-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./wp-content/uploads/2012/02/phot.superposition.png" class="aligncenter img-fluid figure-img" style="width:80.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-phot-superposition-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.13: The color-matching experiment satisfies the principle of superposition. In parts (a) and (b) test lights are matched by a mixture of three primary lights. In part (c) the sum of the test lights is matched by the additive mixture of the primaries, demonstrating superposition.
</figcaption>
</figure>
</div>
<p>We can define the experimental measurements in the color-matching experiment in direct analogy with the definitions we used in the scotopic matching experiment. The input variable in the color-matching experiment is the light <span class="math inline">\(\mathbf{t}\)</span>, just as in scotopic matching. In the color-matching experiment, however, the subject’s responses consist of three numbers, not just one. So, we record the responses using a three-dimensional vector, <span class="math inline">\(\mathbf{e}\)</span>. The entries of <span class="math inline">\(\mathbf{e}\)</span> are the intensities of the three primary lights <span class="math inline">\(( e{1} , e{2} , e{3} )\)</span>. To test superposition in the color-matching experiment we follow the logic illustrated in <a href="#fig-phot-superposition" class="quarto-xref">Figure&nbsp;<span>4.13</span></a>. We obtain a match to a <span class="math inline">\(\mathbf{t}\)</span> by adjusting the primary intensities to the levels in <span class="math inline">\(\mathbf{e}\)</span>. We then obtain a match to <span class="math inline">\(\mathbf{t} '\)</span> by adjusting the three primary intensities to <span class="math inline">\(\mathbf{e} '\)</span>. We test additivity by verifying that the match to <span class="math inline">\(\mathbf{t} + \mathbf{t} '\)</span>; is <span class="math inline">\(\mathbf{e} + { \mathbf{e} '}\)</span>. Photopic color-matching satisfies homogeneity and superposition. We honor the person who first understood the importance of superposition in color-matching by calling this empirical property <em>Grassmann’s additivity law</em>.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./wp-content/uploads/2012/02/photopic.png" class="img-fluid figure-img" style="width:80.0%"></p>
<figcaption>Matrix tableau of color-matching. The photopic color-matching experiment defines a linear mapping from the test light spectral power distribution to the intensity of the three primary lights. The rows of the system matrix are called the color-matching functions. These functions can be estimated by setting matches to many different test lights and solving a set of linear equations.</figcaption>
</figure>
</div>
<p>Because the color-matching experiment linearly maps the physical stimulus <span class="math inline">\(\mathbf{t}\)</span> to the primary intensities, <span class="math inline">\(\mathbf{e}\)</span>, there must be a system matrix that maps the input vector <span class="math inline">\(\mathbf{t}\)</span> to the output vector <span class="math inline">\(\mathbf{e}\)</span>. The matrix tableau shows the input-output relationship for the photopic color-matching experiment in matrix tableau. We will call the <span class="math inline">\(3 \times n_{\lambda}\)</span> system matrix <span class="math inline">\(\mathbf{C}\)</span>.</p>
<p>We can estimate the system matrix <span class="math inline">\(\mathbf{C}\)</span> from the color-matches in the same way as we estimated the scotopic system matrix: by setting matches to a collection of monochromatic test lights with unit intensity. Since the vector representing a monochromatic test light is zero at each entry but one, the product of the system matrix and the monochromatic test light vector equals a single column of the system matrix. Thus, by matching a series of unit intensity monochromatic lights, we can define each of the columns of the system matrix, <span class="math inline">\(\mathbf{C}\)</span>.</p>
<p>It is also useful to think of the system matrix in terms of its rows, which are called the <em>color-matching functions</em>. Each row of the matrix defines the intensity of a single primary light that was set to match the monochromatic test lights. We will relate the rows of the photopic system matrix to the properties of the cone photopigments just as we related the single row of the scotopic system matrix to the rhodopsin photopigment. However, to make the connection between the cone photopigments and the color-matching functions will require a little more work.</p>
<section id="measurements-of-the-color-matching-functions" class="level3">
<h3 class="anchored" data-anchor-id="measurements-of-the-color-matching-functions">Measurements of the Color-Matching Functions</h3>
<p>Two important caveats arise when we measure the color-matching functions. These are only a minor theoretical nuisance, but they have important implications for the laboratory experiment and for practical applications.</p>
<p>The first issue concerns the selection primary lights. We should chose lights that are visually <em>independent</em>: that is, no additive mixture of two of the primary lights should be a visual match to the third primary. This is an obvious but important constraint: it would be unreasonable to choose the second primary light that looked the same as the first except for an intensity scale factor. This choice would be foolish since we could always replace the second light by an intensity-scaled version of the first primary light, adding nothing to the range of visual matches we can obtain. Similarly, a primary that can be matched by a mixture of the first two adds nothing. We must choose our primary lights so that they are independent of one another.</p>
<p>Even among collections of primary lights that are independent, some are more convenient than others. Empirically, it turns out that no matter which primary lights we choose, there will always be some test lights that cannot be matched by an additive mixture of the three primaries. To match these test lights, we must move one or even two of the primary lights from the matching side of the bipartite field to the test side of the bipartite field. Thus, ordinarily we obtain a visual matches of the form <span id="eq-cmatch1"><span class="math display">\[
\mathbf{t} = e_1 \mathbf{p}_1 + e_2 \mathbf{p}_2 + e_3 \mathbf{p}_3 .
\tag{4.2}\]</span></span></p>
<p>Shifting one of the primaries to the other side of the bipartite field means that our match has the form</p>
<p><span id="eq-cmatch2"><span class="math display">\[
\mathbf{t} + e_1 \mathbf{p}_1 = e_2 \mathbf{p}_2 + e_3 \mathbf{p}_3 .
\tag{4.3}\]</span></span></p>
<p>To a mathematician, <a href="#eq-cmatch2" class="quarto-xref">Equation&nbsp;<span>4.3</span></a> is the same as</p>
<p><span id="eq-cmatch3"><span class="math display">\[
\mathbf{t} = - e_1 \mathbf{p}_1 + e_2 \mathbf{p}_2 + e_3 \mathbf{p}_3 .
\tag{4.4}\]</span></span></p>
<p>Hence, when we encode the intensity of the primary light that has been shifted to the other side of the test field we denote the match using a negative intensity value<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>.</p>
<div id="fig-cie-rgb" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-cie-rgb-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./wp-content/uploads/2012/02/cie.rgb_.png" class="img-fluid figure-img" style="width:60.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-cie-rgb-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.14: The color-matching functions are the rows of the color-matching system matrix. The functions measured by <span class="citation" data-cites="stiles-colourmatching1959">Stiles and Burch (<a href="references.html#ref-stiles-colourmatching1959" role="doc-biblioref">1959</a>)</span> using a 10 deg bipartite field and primary lights at the wavelengths 645.2 nm, 526.3 nm, and 444.4 nm with unit radiant power are shown.
</figcaption>
</figure>
</div>
<p><a href="#fig-cie-rgb" class="quarto-xref">Figure&nbsp;<span>4.14</span></a> plots color-matching functions measured by <span class="citation" data-cites="stiles-colourmatching1959">Stiles and Burch (<a href="references.html#ref-stiles-colourmatching1959" role="doc-biblioref">1959</a>)</span> using three monochromatic primary lights at 645.2 nm, 525.3 nm and 444.4 nm. Each function describes the intensity of one of the primary lights used to match various monochromatic test lights. Notice that the intensity of the red primary, at 645.2 nm nm, is negative over a region of test light wavelengths, indicating that over this range of test lights the 645.2 nm primary light was added to the test field.</p>
<p>The color-matching functions are extremely important in color technology, such as creating images on color monitors and color printers. I review the application of these methods to color monitors in the Appendix.</p>
</section>
<section id="uniqueness-of-the-color-matching-functions" class="level3">
<h3 class="anchored" data-anchor-id="uniqueness-of-the-color-matching-functions">Uniqueness of the Color-Matching Functions</h3>
<p>Suppose two research groups measure the color-matching functions using different sets of primary lights. One group measures the color-matching functions using three primary lights <span class="math inline">\(\mathbf{p}_{i}\)</span>, while the second group uses a different set of primary lights, <span class="math inline">\(\mathbf{p}_{i}'\)</span>. How will the two sets of color matching functions be related?</p>
<p>We can answer this question by the following thought experiment. First, create a matrix whose columns contain the spectral power distributions of the first group’s primary lights, and call this matrix <span class="math inline">\(\mathbf{P}\)</span>. The spectral power distribution of a mixture of the primaries, with primary intensities <span class="math inline">\(\mathbf{e}\)</span>, is the weighted sum of the columns. We can express this mixture using the matrix product <span class="math inline">\(\mathbf{P} \mathbf{e}\)</span>. Now, we can use the color-matching functions to predict when a test light will match the mixture of three primaries. The test and primaries will match when</p>
<p><a name="id193940126"></a></p>
<p><span id="eq-photopic-match"><span class="math display">\[
\mathbf{C} \mathbf{t} = \mathbf{C} \mathbf{P} \mathbf{e}
\tag{4.5}\]</span></span></p>
<p>Suppose the second group of researchers can also established matches to this test light using their primaries. To describe their measurements, we create a second matrix whose columns contain the spectral power distributions of the second group’s primary lights, <span class="math inline">\(\mathbf{P}'\)</span>. Call the primary intensities used to match the test with the second primaries <span class="math inline">\(\mathbf{e}'\)</span>. Since the light <span class="math inline">\(\mathbf{P}' \mathbf{e}'\)</span> is a visual matched to the test light, we know that</p>
<p><span id="eq-photopic-match2"><span class="math display">\[
\mathbf{C} \mathbf{t} = \mathbf{C} \mathbf{P}' \mathbf{e}'
\tag{4.6}\]</span></span></p>
<p>By combining <a href="#eq-photopic-match" class="quarto-xref">Equation&nbsp;<span>4.5</span></a> and <a href="#eq-photopic-match2" class="quarto-xref">Equation&nbsp;<span>4.6</span></a>, we find that the two vectors of primary intensities, <span class="math inline">\(\mathbf{e}\)</span> and <span class="math inline">\(\mathbf{e}'\)</span>, are related by a linear transformation,</p>
<p><span id="eq-photopic-transform"><span class="math display">\[
\mathbf{e} = (\mathbf{C} \mathbf{P} )^{-1}\mathbf{C} \mathbf{P}' \mathbf{e}'
\tag{4.7}\]</span></span></p>
<p>With a little more algebra, one can show that the color-matching functions are related by the following linear transformation:</p>
<p><span id="eq-photopic-transform2"><span class="math display">\[
\mathbf{C} = ( \mathbf{C} \mathbf{P}') \mathbf{C}'
\tag{4.8}\]</span></span></p>
<p>The <span class="math inline">\(3 \times 3\)</span> matrix relating the two sets of color-matching functions, <span class="math inline">\(\mathbf{C} \mathbf{P}'\)</span>, has a simple empirical interpretation; its columns contain the intensities of the new primaries needed to match the original primaries. To see this, remember that each column of <span class="math inline">\(\mathbf{P}'\)</span> is the spectral power distribution of one of the primary lights, <span class="math inline">\(\mathbf{p}_i'\)</span>. Thus, the first column of <span class="math inline">\(\mathbf{C} \mathbf{P}'\)</span> is the vector of intensities of the first group of primaries needed to match <span class="math inline">\(\mathbf{p}_1'\)</span>. Similarly, the second and third columns of <span class="math inline">\(\mathbf{C} \mathbf{P}'\)</span> contain the intensities of the first group of primaries needed to match the corresponding primaries in <span class="math inline">\(\mathbf{P}'\)</span>. The matrix <span class="math inline">\(\mathbf{C} \mathbf{P}'\)</span> contains three columns equal to the primary intensities of <span class="math inline">\(\mathbf{p}_i\)</span> needed to match the new primary lights, <span class="math inline">\(\mathbf{p}_i'\)</span>.</p>
<p>The photopic color-matching functions are not unique; when we measure using different sets of primaries we will obtain different color-matching functions. But, the color-matching functions are not completely free to vary either, since different pairs of color-matching functions will always be related by a linear transformation. We say that the color-matching functions are unique up to a free linear transformation</p>
</section>
<section id="a-standard-set-of-color-matching-functions" class="level3">
<h3 class="anchored" data-anchor-id="a-standard-set-of-color-matching-functions">A Standard Set of Color-Matching Functions</h3>
<p>When the members of the Committe Internationale d’Eclairage (CIE; an international standards organization) met in 1931, they were fully aware that the color-matching functions were not unique. To facilitate communication about color, the CIE defined a standard system of color representation based on one particular set of color-matching functions, that everyone should use. This set of color-matching functions defines the <em>XYZ tristimulus coordinate system</em>. The color-matching functions in this system are called <span class="math inline">\(\bar{x}(\lambda)\)</span>, <span class="math inline">\(\bar{y}(\lambda)\)</span>, and <span class="math inline">\(\bar{z}(\lambda)\)</span> respectively. They define one of the many possible system matrices of the color-matching experiment. <a href="#fig-xyz" class="quarto-xref">Figure&nbsp;<span>4.15</span></a> shows the three standard color-matching functions, <span class="math inline">\(\bar{x}(\lambda)\)</span>, <span class="math inline">\(\bar{y}(\lambda)\)</span>, and <span class="math inline">\(\bar{z}(\lambda)\)</span>.</p>
<div id="fig-xyz" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-xyz-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./wp-content/uploads/2012/02/XYZ.png" class="img-fluid figure-img" style="width:80.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-xyz-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.15: The XYZ standard color-matching functions. In 1931 the CIE standardized a set of color-matching functions for image interchange. These color-matching functions are called <span class="math inline">\(\bar{x}(\lambda)\)</span>, <span class="math inline">\(\bar{y}(\lambda)\)</span>, and <span class="math inline">\(\bar{z}(\lambda)\)</span>. Industrial applications commonly describe the color properties of a light source using the three primary intensities needed to match the light source that can be computed from the XYZ color-matching functions.
</figcaption>
</figure>
</div>
<p>The standard color-matching functions were chosen for several reasons. First, <span class="math inline">\(\bar{y}(\lambda)\)</span> is a rough approximation to the brightness of monochromatic lights of equal size and duration. A second important reason is that the functions are non-negative, which simplified some aspects of the design of instruments to measure the tristimulus coordinates. But, as with any standards decision, there are some irritating aspects of the XYZ color-matching functions as well. One serious drawback is that there is no set of physically realizable primary lights that by direct measurement will yield the color-matching functions. Primary lights that would yield these functions would have to have negative energy at some wavelengths and cannot be instrumented. Another problem is that these early estimates have been improved upon. Specifically, <span class="citation" data-cites="judd1951a-visualstimulus">Judd (<a href="references.html#ref-judd1951a-visualstimulus" role="doc-biblioref">1951</a>)</span> noted that the functions are inaccurate in the short-wavelength region and he proposed a modified set of functions that are often used by scientists, although they have not displaced the industrial standard. Also, and perhaps most significantly, there is very little that is intuitive about the XYZ color-matching functions. Although they have served us quite well as a technical standard, and are understood by the mandarins of our discipline, they have served us quite poorly in explaining the discipline to new students and colleagues.</p>
</section>
<section id="the-biological-basis-of-photopic-color-matching" class="level3">
<h3 class="anchored" data-anchor-id="the-biological-basis-of-photopic-color-matching">The Biological Basis of Photopic Color-matching</h3>
<p>Just as we can explain the scotopic color-matching experiment in terms of the light absorption properties of the rhodopsin photopigment, we also would like to explain the photopic color-matching experiment in terms of the light absorption properties of the cone photopigments. We related the photopigments and the behavior by studying the system matrices of the two experiments. We found that two lights were scotopic matches when <span class="math inline">\(\mathbf{R} \mathbf{t} = \mathbf{R} \mathbf{t}'\)</span>, and we then showed that the entries in the <span class="math inline">\(1 \times n_{\lambda}\)</span> scotopic matching matrix, <span class="math inline">\(\mathbf{R}\)</span>, was the same as the rhodopsin absorption function <span class="math inline">\(\mathbf{A}\)</span>. For photopic vision, we use the same general approach. But, there are two complications: there are three cone photopigments, not just one; the photopic matching matrix is not unique.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./wp-content/uploads/2012/02/ch4_181.png" class="align-center img-fluid figure-img" style="width:80.0%"></p>
<figcaption>Cone photopigments and the color-matching functions. If we measure the wavelength sensitivity of each of the cone photopigments, we can create a <span class="math inline">\(3 \times N\)</span> system matrix to describe the cone absorptions. Then, we can evaluate whether the cone absorption system matrix can serve to explain the results of the color-matching experiment.</figcaption>
</figure>
</div>
<p>Extending our analysis to account for three cone photopigments instead of one rod photopigment is straightforward. We measure the absorption properties of each of the three cone photopigments, and we create a system matrix, <span class="math inline">\(\mathbf{B}\)</span>, with three rows to define the three cone photopigment absorption functions. This matrix generalizes the rhodopsin system matrix <span class="math inline">\(\mathbf{A}\)</span>. Then, we compare the cone absorption system matrix, <span class="math inline">\(\mathbf{B}\)</span>, with the color-matching experiment system matrix, <span class="math inline">\(\mathbf{C}\)</span>. We must evaluate whether the cone photopigment matrix can explain the color-matching data.</p>
<p>From our analysis of color-matching, we know that the color-matching system matrix is not unique; there is a collection of equivalent system matrices, all related by a linear transformation. Hence, to evaluate whether the cone absorption matrix can explain the color-matching experiment, we must evaluate whether the color-matching system matrix, <span class="math inline">\(\mathbf{C}\)</span>, is related to <span class="math inline">\(\mathbf{B}\)</span> by a linear transformation. Our next task, then, is to measure the cone absorption system matrix, <span class="math inline">\(\mathbf{B}\)</span>.</p>
</section>
<section id="measuring-cone-photocurrents" class="level3">
<h3 class="anchored" data-anchor-id="measuring-cone-photocurrents">Measuring Cone Photocurrents</h3>
<p>Currently, the best estimate of the cone photopigment absorptions is derived from measurements of the cone photocurrent, that is the change in the current flow through the membrane of individual cones as they are stimulated by light. Relating the photocurrent to the photopigment absorptions requires some careful analysis because the photocurrent depends nonlinearly on the photopigment absorptions in the cone. In this section we will develop new theoretical methods to interpret the nonlinear cone photocurrent measurements and infer the linear properties of the cone photopigments.</p>
<div id="fig-toad-electrode" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-toad-electrode-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./wp-content/uploads/2012/02/toadElectrode-updated.png" class="img-fluid figure-img" style="width:60.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-toad-electrode-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.16: Measurement instruments for detecting the photocurrent generated by a macaque photoreceptor. The image shows a portion of the retina suspended in solution. A single photoreceptor from this retinal section has been drawn into the microelectrode and is being stimulated by a beam of light passing transversely through the photoreceptor and microelectrode (Image courtesy of D. Baylor).
</figcaption>
</figure>
</div>
<p><span class="citation" data-cites="baylor-macaque1987">Baylor et al. (<a href="references.html#ref-baylor-macaque1987" role="doc-biblioref">1987</a>)</span> and <span class="citation" data-cites="baylorphotoreceptorsignalsvision1987">Baylor (<a href="references.html#ref-baylorphotoreceptorsignalsvision1987" role="doc-biblioref">1987</a>)</span> were the first to measure the cone photocurrents in the macaque retina. The macaque has three types of cones and its behavior on most color tasks is quite similar to human behavior Thus, the comparison between the properties of the macaque photoreceptors and human behavior is a good place to begin (<span class="citation" data-cites="devaloisjacobs1971">De Valois and Jacobs (<a href="references.html#ref-devaloisjacobs1971" role="doc-biblioref">1971</a>)</span>).</p>
<p>To measure the cone photocurrent, Baylor, Nunn and Schnapf removed the retina from the eye and chopped it into fine pieces about 100 <span class="math inline">\(\mu\)</span>m across. The pieces are placed in a chamber containing special solutions that support the metabolism of the cells. Even though the retina has been dissected from the eye and chopped into pieces, the electrical response of the photoreceptors remains vigorous for several hours. Baylor and his colleagues recorded the photocurrent of individual cells using the experimental technique pictured in <a href="#fig-toad-electrode" class="quarto-xref">Figure&nbsp;<span>4.16</span></a>. The figure shows a glass micropipette approaching a single photoreceptor. The inner diameter of the micropipette is between 2 and 6 <span class="math inline">\(\mu\)</span>m, only ten times as wide as the wavelength of visible light. A single photoreceptor outer segment is held inside the micropipette, and there is a thin ray of light passing transversely through the photoreceptor and stimulating it.</p>
<div id="fig-cone-timecourse" class="align-center quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-cone-timecourse-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./wp-content/uploads/2012/02/cone.timecourse.png" class="align-center img-fluid figure-img" style="width:80.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-cone-timecourse-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.17: The timecourse of cone photocurrent in response to a brief test flash is biphasic. The amplitude of the photocurrent response increases with the stimulus intensity. The response functions are the same for different wavelengths of light, such as at 500 nm and 659 nm in parts (a) and (b), respectively. The stimulus timecourse is shown below the photocurrent plots. (Source: <span class="citation" data-cites="baylor-macaque1987">Baylor et al. (<a href="references.html#ref-baylor-macaque1987" role="doc-biblioref">1987</a>)</span>)
</figcaption>
</figure>
</div>
<p><a href="#fig-cone-timecourse" class="quarto-xref">Figure&nbsp;<span>4.17</span></a> shows the result of stimulating the photoreceptor with a brief impulse of light. The curves illustrate the membrane photocurrent following a brief light flash. The curves in part (a) of the figure plot the response to 500 nm light at a range of intensities. The curves in part (b) plot the response to 659 nm light at a range of intensities. Before the stimulus is presented, there is a steady inward flow of current consisting of a stream of positively charged sodium ions entering the photoreceptor through ion channels in the cell membrane. This steady level in the absence of light is called the dark current. It represents a baseline level and is denoted as zero in the graph. The plotted values are biphasic, varying both above and below the baseline.</p>
<p>When the photopigment absorbs light from the flash, the inward flow of sodium ions is slowed. The sodium current in darkness reduces the negative electrical polarization of the cell interior. When light blocks the inward flow, the negative voltage difference between the inside and outside of the cell increases. Thus, the initial photoreceptor response to light is a hyperpolarization. After the initial blockage of inward flowing sodium current, the current flow is actively restored. The mechanism that restores balance overcompensates; during the second phase of the response the total photocurrent flow reverses direction. Thus the photocurrent response first flows in one direction and then the opposite direction, leading to the biphasic impulse response.</p>
<p>In this experiment the test light is the input, <span class="math inline">\(\mathbf{t}\)</span>, and the cone photocurrent response is the output. We can evaluate whether the input-output relationship satisfies one of the requirements of a linear system, homogeneity, from the graphs in <a href="#fig-cone-timecourse" class="quarto-xref">Figure&nbsp;<span>4.17</span></a>. Suppose the input signal is <span class="math inline">\(\mathbf{t}\)</span> and the photocurrent response is <span class="math inline">\(\mathbf{c}\)</span>, a vector representing the photocurrent as a function of time following the stimulus. To test homogeneity we should measure the response to the scaled input, <span class="math inline">\(k \mathbf{t}\)</span>. If the system is linear, then we expect that the photocurrent response will be <span class="math inline">\(k \mathbf{c}\)</span>. From a visual inspection of the curves in <a href="#fig-cone-timecourse" class="quarto-xref">Figure&nbsp;<span>4.17</span></a> we can see that homogeneity fails. There are two features of the curves that should make this evident to you. First, notice that as the test intensity increases, the peak deviation reaches a maximum of about 25 pA and then saturates. Saturation is inconsistent with a strictly linear relationship between input intensity and output photocurrent. A second way to see that linearity fails is to consider the point of the biphasic response at which the output crosses the zero level at baseline. If the output photocurrent is proportional to the input intensity, points with a zero response level should always have a zero response level: multiplying zero by any intensity still yields zero. Hence, we expect that the zero-crossing should not change its position as we increase the test intensity. This prediction is true for lower test intensities, but as the input intensity increases to fairly high levels, the zero-crossing shifts its position in time.</p>
<p>How surprising: Human performance in the color-matching experiment satisfies the principles of a linear system, homogeneity and superposition, yet the cone photocurrent responses a part of the chain of biological events that mediate the behavior, fail the simplest tests of linearity. How can the behavior be linear when the components mediating the behavior are nonlinear? We will answer this question in the following section. The answer is given specifically for color-matching, but the principles we will review are quite general. They will be helpful again when we consider the relationship between behavior and other neural responses throughout this book.</p>
</section>
<section id="static-nonlinearities-photocurrents-and-photopigments" class="level3">
<h3 class="anchored" data-anchor-id="static-nonlinearities-photocurrents-and-photopigments">Static Nonlinearities: Photocurrents and Photopigments</h3>
<div id="fig-univariance" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-univariance-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./wp-content/uploads/2012/02/univariance.png" class="img-fluid figure-img" style="width:60.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-univariance-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.18: The principle of univariance states that a photon absorption leads to the same neural response, no matter what the wavelength of the photon. The principle predicts that two stimuli at different wavelengths can be adjusted to equate the photocurrent response throughout its timecourse. This is shown here as the match between photocurrents in response to 550 nm (dashed) and 659 nm (solid) test lights set to a nine to one intensity ratio (Source: <span class="citation" data-cites="baylor-macaque1987">Baylor et al. (<a href="references.html#ref-baylor-macaque1987" role="doc-biblioref">1987</a>)</span>).
</figcaption>
</figure>
</div>
<p>By comparing the sets of photocurrent responses on the top and bottom of <a href="#fig-cone-timecourse" class="quarto-xref">Figure&nbsp;<span>4.17</span></a>, it appears that as we vary the level of the test signal we sweep out the same set of curves. The similarity of the measured photocurrent responses to the two test lights suggests that we can perform a color-matching experiment at the level of the photocurrent response. We can perform such an experiment by choosing a test light and a primary light and adjusting the intensity of the primary light light until the photocurrent responses of the test and primary are the same. The curves in <a href="#fig-univariance" class="quarto-xref">Figure&nbsp;<span>4.18</span></a> show one example of such a match using a primary light at 500 nm and a test light at 659 nm.</p>
<div id="fig-phot-homogeneity" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-phot-homogeneity-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./wp-content/uploads/2012/02/phot.homogeneity.png" class="img-fluid figure-img" style="width:60.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-phot-homogeneity-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.19: A matching experiment using the cone photocurrent as response. Lights at different wavelengths have equivalent effects on the cone photocurrent when the light intensity ratio is set properly. For this cone, the 659 nm light must be nine times more intense than the 500 nm light to have an equivalent effect (Source: <span class="citation" data-cites="baylor-macaque1987">Baylor et al. (<a href="references.html#ref-baylor-macaque1987" role="doc-biblioref">1987</a>)</span>).
</figcaption>
</figure>
</div>
<p>The physiological preparation is very delicate and it is difficult to keep the photoreceptors alive and functioning. This makes it impossible to set full photocurrent matches for arbitrary test and primary combinations. But, it is possible to carry out an efficient approximation of the full experiment. The two curves in <a href="#fig-phot-homogeneity" class="quarto-xref">Figure&nbsp;<span>4.19</span></a> summarize the photocurrent responses to a 659 nm test light and the 500nm primary light at a series of different intensity levels. The data points shows the peak value of the photocurrent response as a function of intensity; the peak value summarizes the full photocurrent timecourse. The smooth curves drawn through the points interpolate the peak response at any intensity level. From these interpolated measurements, we can estimate the intensity levels needed to obtain complete matches between the test and primary lights.</p>
<p>If the matching experiment performed at the level of the photocurrent satisfies homogeneity, the intensity of the test and primary lights that match should be proportional to one another. We can estimate the intensity of the test and primary lights that match at different response levels by drawing a horizontal line across the graph and noting the intensity levels that produce the same peak photocurrent. The curves through the two sets of data points in <a href="#fig-phot-homogeneity" class="quarto-xref">Figure&nbsp;<span>4.19</span></a> are parallel on a logarithmic intensity axis, so that the intensities of pairs of points that match are separated by a constant amount. Since the axis is logarithmic, equal separation implies that when the photocurrents match the test and primary light intensities are in a particular ratio, precisely as required by homogeneity. Hence, the photocurrent matching experiment satisfies homogeneity even though the photocurrent response itself is nonlinear.</p>
<p>From the separation between the two curves, we see that more 659 nm photons are needed than 500 nm photons to evoke the same response. For this pair of wavelengths the curves are separated by <span class="math inline">\(0.97\)</span> log units that corresponds to a ratio of <span class="math inline">\(9.3\)</span>. It takes <span class="math inline">\(9.3\)</span> times as many 659 nm quanta to equal the photocurrent produced by a number of 500 nm quanta. By repeating this experiment using test lights at many different wavelengths, we can estimate the complete spectral responsivity curves for the cone photoreceptors. From a collection of such measurements we can estimate the wavelength sensitivity of the cone receptor. The wavelength sensitivity is due to the properties of the cone photopigment, so in this way we can derive the cone photopigment absorption function from the photocurrent measurements.</p>
<div id="fig-cone-sp-sens" class="align-center quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-cone-sp-sens-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./wp-content/uploads/2012/02/cone.sp_.sens_.png" class="align-center img-fluid figure-img" style="width:60.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-cone-sp-sens-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.20: Cone photocurrent spectral responsivities. The measurement range spans a factor of one million. The S cone sensitivity at short wavelengths is high compared to behavioral measurements because in behavioral conditions the lens absorbs short wavelength light strongly. (After <span class="citation" data-cites="baylorphotoreceptorsignalsvision1987">Baylor (<a href="references.html#ref-baylorphotoreceptorsignalsvision1987" role="doc-biblioref">1987</a>)</span>).
</figcaption>
</figure>
</div>
<p>The reader will not be surprised to learn that Baylor, Nunn and Schnapf found cones with three distinct spectral response functions: these measurements are plotted in <a href="#fig-cone-sp-sens" class="quarto-xref">Figure&nbsp;<span>4.20</span></a>. Notice that the vertical axis spans six logarithmic units, so that they measured sensitivities varying over a factor of one million, an extraordinary technical measurement achievement.</p>
</section>
<section id="static-nonlinearities-the-principle" class="level3">
<h3 class="anchored" data-anchor-id="static-nonlinearities-the-principle">Static Nonlinearities: The principle</h3>
<p>We can analyze the photopigment sensitivity from the photocurrent response because the nonlinear relationship between the test light and the photocurrent signal is very simple: The photons are absorbed by a linear process; the linear encoding is followed by a nonlinear process that converts the photopigment absorption rate into membrane photocurrent. The properties of the nonlinear process are independent of the linear encoding step, and thus we call this process a static nonlinearity. When a system is a linear process followed by a static nonlinearity, we can characterize the system performance completely.</p>
<p>It is worth spending a little time thinking about why we can characterize this type of nonlinear system. First, consider the linear process of photopigment absorption. There is a photopigment system matrix, say, <span class="math inline">\(\mathbf{A}\)</span>, that maps the test light into a photon absorption rate, <span class="math inline">\(\mathbf{A} \mathbf{t}\)</span>. Second, the static nonlinearity converts the photopigment absorption rate into a peak photocurrent response. Together, these two processes define the nonlinear system response, <span class="math inline">\(F(\mathbf{A} \mathbf{t})\)</span>.</p>
<p>When we set a match between the peak photocurrent from the test light and the primary light, we establish an equation of the form</p>
<p><span id="eq-static-nonlinearity"><span class="math display">\[
F(\mathbf{A} \mathbf{t}) = F(a \mathbf{A} \mathbf{p})
\tag{4.9}\]</span></span></p>
<p>where <span class="math inline">\(a\)</span> is the intensity of the primary light needed to match the test light. Since the nonlinear function <span class="math inline">\(F\)</span> is monotonic, we can remove it from both sides of <a href="#eq-static-nonlinearity" class="quarto-xref">Equation&nbsp;<span>4.9</span></a> and write</p>
<p><span id="eq-static-nonlinearity-linear"><span class="math display">\[
\mathbf{A} \mathbf{t} = a \mathbf{A} \mathbf{p}
\tag{4.10}\]</span></span></p>
<p>From this equation we see that there is a linear relationship between the primary and test light intensities, since if <span class="math inline">\(\mathbf{t}\)</span> matches <span class="math inline">\(a \mathbf{p}\)</span>, then <span class="math inline">\(k \mathbf{t}\)</span> will match <span class="math inline">\(k a \mathbf{p}\)</span>. Thus, even if a system has a static nonlinearity, the system’s performance in a matching experiment will satisfy the test of homogeneity. We can also show that in a matching experiment a system with a static nonlinearity will satisfy superposition.</p>
</section>
<section id="cone-photopigments-and-color-matching" class="level3">
<h3 class="anchored" data-anchor-id="cone-photopigments-and-color-matching">Cone Photopigments and Color-matching</h3>
<p>How well do the spectral sensitivity of the cone photopigments predict performance in the photopic color-matching experiment? We predict that two lights are metamers when they have the same effect on the three types of cone photopigments. To answer how well the cone photopigments predict the color-matching results, we can perform the following calculation.</p>
<div id="fig-cone-to-cie" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-cone-to-cie-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./wp-content/uploads/2012/02/cone.to_.cie_1.png" class="img-fluid figure-img" style="width:60.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-cone-to-cie-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.21: Comparison of cone photocurrent responses and the color-matching functions. The cone photocurrent spectral responsivities are within a linear transformation of the color-matching functions, after a correction has been made for the optics and inert pigments in the eye. The smooth curves show the <span class="citation" data-cites="stiles-colourmatching1959">Stiles and Burch (<a href="references.html#ref-stiles-colourmatching1959" role="doc-biblioref">1959</a>)</span> 10 deg color-matching functions. The symbols show the matches predicted from the photocurrents of the three monkey cones. The predictions included a correction for absorption by the lens and other inert pigments in the eye (Source: <span class="citation" data-cites="baylorphotoreceptorsignalsvision1987">Baylor (<a href="references.html#ref-baylorphotoreceptorsignalsvision1987" role="doc-biblioref">1987</a>)</span>).
</figcaption>
</figure>
</div>
<p>Create a matrix, <span class="math inline">\(\mathbf{B}\)</span>, whose three rows are the cone photopigment spectral sensitivities. We use this matrix to calculate the cone absorptions to a test light, so that <span class="math inline">\(\mathbf{B} \mathbf{t}\)</span> is a <span class="math inline">\(3 \times 1\)</span> vector containing the cone sensitivities to the test light. We predict that two lights <span class="math inline">\(\mathbf{t}\)</span> and <span class="math inline">\(\mathbf{t}'\)</span> will be a visual match when they have equivalent effects on the cone photopigments. Thus, two lights will be metamers when</p>
<p><span class="math display">\[
\mathbf{B} \, \mathbf{t} = \mathbf{B} \, \mathbf{t}'
\]</span></p>
<p>It follows that the cone absorption matrix <span class="math inline">\(\mathbf{B}\)</span> is a system matrix for the color-matching experiment. This is precisely what we mean when we say that the cone photopigments can explain the color-matching experiment. Earlier in this chapter, we showed that the color-matching functions are all related by a <span class="math inline">\(3 \times 3\)</span> linear transformation. Thus, there should be a linear transformation, say <span class="math inline">\(\mathbf{Q}\)</span>, that maps the cone absorption curves to the system matrix of the color-matching experiment, namely <span class="math inline">\(\mathbf{C} = \mathbf{Q} \, \mathbf{B}\)</span>.</p>
<p>Baylor, Nunn and Schnapf made this comparison<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>. They found a linear transformation to convert their cone photopigment measurements into the color-matching functions. <a href="#fig-cone-to-cie" class="quarto-xref">Figure&nbsp;<span>4.21</span></a> shows the color-matching functions along with the linearly transformed cone photopigment sensitivity curves. From the agreement between the two data sets, we can conclude that the photopigment spectral responsivities are a satisfactory biological basis to explain the photopic color-matching experiment.</p>
</section>
<section id="why-this-is-a-big-deal" class="level3">
<h3 class="anchored" data-anchor-id="why-this-is-a-big-deal">Why this is a big deal</h3>
<p>The methods we have used to connect cone photopigments and color-matching are a wonderful example of how to relate physiological and behavioral data precisely. To make the connection between the behavioral and physiological data we have had to reason through some challenging issues. Still, we have obtained a close quantitative agreement between the behavioral and physiological measurements.</p>
<p>Notice that as we began our analysis, the properties of the neural measurements and the behavioral measurements appeared different. The linearity of the color-matching experiment contrasts with the nonlinearity of the photocurrent response. But by comparing stimuli that cause equal-performance responses, rather than comparing behavioral matches with raw photocurrent levels, we can see past the dissimilarities and understand their profound relationship. In this case, we know how to connect these two different measurements and the simplicity and clarity of the relationship is easy to see. It makes sense, then, to ask what we can learn from this successful analysis that might help us when we move on to try to relate other behavioral and biological measurements.</p>
<p>We should remember that the relationship between behavior and biology may not always be found at the level of the measurements that are natural within each discipline. Direct comparisons between the intensity of the primary lights and the photocurrent signals do not help us to explain the relationship, even though each measure is natural within its own experiment. To make a deep connection we needed to look at the structural properties of the experiment. When we perform the color-matching experiment, we learn about the equivalence of different stimuli. This equivalence is preserved under many transformations. Thus, we succeed at comparing the behavior and the biology when we compare the results at this level, although they seem different when we use other quantitative measures.</p>
<p>How do we know when we have the right set of biological and behavioral measures? There are many related physiological measures we might use to characterize the photoreceptors, and there are many variants of the behavioral color-matching experiment. For example, we could have asked the subject whether the brightness of the test light doubles when we double the intensity (the answer is no). Or we could have asked the subject to assess the change in redness or greenness. Just as the input-output relationship of the photocurrent may violate linearity for intense stimuli, so too many behavioral measures violate linearity. Finding the right measures to reveal the common properties of the two data sets is in part science and in part art. We learn about connections between these disciplines by trying to recast our experiments using different methods until the relationships become evident.</p>
<p>As we study the neural response in more central parts of the nervous system, you may be tempted to interpret a physiological measurement as a direct predictor of some percept. The rate at which a neuron responds or the stimulus that drives a neuron powerfully are natural biological measures. Remember, however, that there is no simple relationship between the photocurrent response and the intensity level of a primary light. We achieved a good link between the physiological and behavioral measures by structuring a theory of the information that is preserved in each set of experimental measurements. Understanding our measurements in terms of this level of abstraction — what information is present in the signal — is a harder but better way to forge links between different disciplines. Color science has been fortunate to have workers in both disciplines who seek to forge these links. We should take advantage of their experience when we relate behavior and biology in other domains.</p>
</section>
</section>
<section id="color-deficiencies" class="level2" data-number="4.4">
<h2 data-number="4.4" class="anchored" data-anchor-id="color-deficiencies"><span class="header-section-number">4.4</span> Color Deficiencies</h2>
<p>I have emphasized the fact that for most observers color-matching under the standard viewing conditions requires three primary lights to form a match and we call color vision <em>trichromatic</em>. There are some viewing conditions in which only two different primary lights are necessary. Under these viewing conditions, color vision is <em>dichromatic</em>. Finally, when only a single primary is required, as under rod viewing conditions, performance is <em>monochromatic</em>.</p>
<section id="small-field-dichromacy" class="level3">
<h3 class="anchored" data-anchor-id="small-field-dichromacy">Small field dichromacy</h3>
<p>Perhaps the most important of case of dichromacy occurs when we reduce the size of the bipartite field used in the color-matching experiment. If the field is greatly reduced in size, from 2 degrees to only 20 minutes of visual angle, then observers no longer need three independent primary lights: two primary lights suffice. Under these circumstances, observers act as if they have only two classes of photoreceptors rather than three.</p>
<p>Why should observers behave as if they had only two classes of receptors when the field is very small? If this observation surprises you, go back to <a href="chapter-3-the-photoreceptor-mosaic.html" class="quarto-xref"><span>Chapter 3</span></a> and re-read the section on the S cone mosaic. You will find that there are very few short-wavelength cones, and there are none in the central fovea. Oddly, we encode less about the spectral properties of the incident light in the central fovea than we record just slightly peripheral to the fovea. In the central fovea, people are dichromatic.</p>
</section>
<section id="dichromatic-observers" class="level3">
<h3 class="anchored" data-anchor-id="dichromatic-observers">Dichromatic observers</h3>
<p>Some observers find that they can perform the color-matching experiment using only two primary lights throughout their entire visual field. Such observers are called <em>dichromats</em>. The vast majority of dichromats are male. By studying the family relationships of dichromats, it has been found dichromacy is a sex-linked genetic trait (<span class="citation" data-cites="pokorny1979-book">Pokorny et al. (<a href="references.html#ref-pokorny1979-book" role="doc-biblioref">1979</a>)</span>). Dichromatic observers can be missing the long-wavelength photopigment (<em>protanopes</em>), the middle-wavelength photopigment (<em>deuteranopes</em>), or short-wavelength photopigment (<em>tritanopes</em>). Tritanopes are much more rare than either protanopes or deuteranopes. The difference in the probabilities arises because the gene responsible for the creation of the short-wavelength photopigment is on a different chromosome (<span class="citation" data-cites="nathans1992">Nathans et al. (<a href="references.html#ref-nathans1992" role="doc-biblioref">1992</a>)</span>).</p>
<p>It is possible to use the color-matching functions measured from dichromatic observers to estimate the photoreceptor spectral responsivities. Suppose we have two dichromatic observers: the first observer has only the <span class="math inline">\(R\)</span> and <span class="math inline">\(G\)</span> photoreceptors, and the second observer has only the <span class="math inline">\(R\)</span> and <span class="math inline">\(B\)</span> photoreceptors. Since the photoreceptor sensitivities are linearly related to the color matching functions, a weighted sum of the first observer’s color-matching functions will equal the <span class="math inline">\(R\)</span> cone absorption function, and a different weighted sum of the second observer’s color-matching functions will equal the <span class="math inline">\(R\)</span> cone absorption function, too. This establishes a linear equation we can use to estimate the <span class="math inline">\(R\)</span> cone absorption function. Similarly, from a pair of dichromats who share only the <span class="math inline">\(G\)</span> cones, we can estimate the <span class="math inline">\(G\)</span> cone sensitivity, and so forth.</p>
<section id="pseudoisochromatic-plates." class="level4">
<h4 class="anchored" data-anchor-id="pseudoisochromatic-plates.">Pseudoisochromatic Plates.</h4>
<p>For some purposes, we do not need the complete results of a color matching experiment to learn about the observer’s color vision. A much simpler test for dichromacy is to have a subject examine a set of colored images called the <em>Ishihara Plates</em>. These plates were designed based on the results of the color matching experiment and can be used to identify different types of dichromats based on a few simple judgments.</p>
<p>Each plate consists of a colored test pattern drawn against a colored background. The test and background are both made up of circles of random sizes; the test and background are distinguished only by their colors. Observers with red-green color deficiencies havedifficulty perceiving the test pattern based. Because this test iseasy to administer, it is commonly used as a quick screening tool todiscriminate normals from protanopes and deuteranopes.</p>
</section>
<section id="farnsworth-munsell-100-hue-test" class="level4">
<h4 class="anchored" data-anchor-id="farnsworth-munsell-100-hue-test">Farnsworth-Munsell 100 Hue test</h4>
<p>The <em>Farnsworth-Munsell 100 Hue test</em> is also commonly used to test for dichromacy. In this test, which is much more challenging than the Ishihara plates, the observer is presented with a collection of cylindrical objects, roughly the size of bottle caps and often called <em>caps</em>. The colors of the caps can be organized into a hue circle, from red, to orange, yellow, green, blue-green, blue, purple and back to red. Despite the name of the test, there are a total of 85 caps, each numbered according to its position around the hue circle. The color of the caps differ by roughly equal perceptual steps.</p>
<div id="fig-farnsworth" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-farnsworth-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./wp-content/uploads/2012/02/farnsworth.png" class="img-fluid figure-img" style="width:60.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-farnsworth-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.22: Representing errors in the Farnsworth-Munsell 100 Hue test. Each of the test objects, called caps, is assigned a position around the circle. The error score is indicated by the radial distance of the line from the center of the circle. Observers with normal color vision rarely have an error score greater than two. Errors characteristic of an observer missing the L cone photopigment (protanope), the M cone photopigment (deuteranope) and the S cone photopigment (tritanope) are shown. (Source: <span class="citation" data-cites="kalmus1965">Kalmus (<a href="references.html#ref-kalmus1965" role="doc-biblioref">1965</a>)</span>).
</figcaption>
</figure>
</div>
<p>The observer’s task is to take a random arrangement of the caps and to place them into order around the color circle. At the beginning of the task, four of the caps (1,23,43, and 64) are used to establish anchor points for the color circle. The subject is asked to arrange the remaining color caps “to form a continuous series of colors.”</p>
<p>The hue steps separating the colors of the caps are fairly small; subjects with normal color vision often make mistakes. After the subject finishes sorting the caps, the experimenter computes an error for each of the 85 positions along the hue circle. The error score is equal to the sum of the absolute differences between the number on the cap and its neighbors. For example, in the correct series 1-2-3-4-5-6 the error score for caps 2 through 5 is 2, the smallest error score. With a single misodering, say 1-3-2-4-5-6, the error scores for caps 2 to 4 are 3, and the error score for 5 remains 2. Normal observers do not produce an error greater than 2 or 3 at any location.</p>
<p>The subject’s error scores are plotted at 85 positions on a circular chart as in <a href="#fig-farnsworth" class="quarto-xref">Figure&nbsp;<span>4.22</span></a>. An error score of zero plots at the innermost circle and increasing error scores plot further away from the center. Subjects missing the L cones (protanopes), M cones (deuteranopes), and S cones (tritanopes) show characteristically different error patterns that cluster along different portions of the hue circle.</p>
</section>
</section>
<section id="anomalous-observers" class="level3">
<h3 class="anchored" data-anchor-id="anomalous-observers">Anomalous Observers</h3>
<p>Dichromatic observers have only two types of cones. The slightly larger population of observers, who are called <em>anomalous</em>, have three types of cones and require three primaries in the color-matching experiment. The matches that they set are stable, but they are well outside of the range set by most of the population. These observers have cone photopigments that are slightly different in structure from most of the population, which is why they are called anomalous. The color-matching functions for anomalous observers are not within a linear transformation of the normal color-matching functions. This is equivalent to the experimental observation that lights that visually match for these observers do not match for normal observers, and vice versa.</p>
<p><span class="citation" data-cites="neitz1993-moreconepigments">Neitz et al. (<a href="references.html#ref-neitz1993-moreconepigments" role="doc-biblioref">1993</a>)</span> have argued on genetic grounds that many people contain small amounts of the anomalous photopigments so that there are more than three cone photopigment types in the normal eye. Because the anomalous photopigments are not very different from the normal, it is hard to discern their presence in all but the most sensitive experimental tasks. They attribute the trichromatic behavior in the color-matching experiment to a neural bottleneck rather than a limit on the number of photopigment types. Since the differences between the normal and anomalous photopigments are very small, however, this hypothesis will be difficult to prove or disprove and it will have very little impact on color technologies.</p>
<p>The relationship between anomalous observers and normal observers parallels the relationship between color cameras and normal observers. The spectral responsivities of the color sensors in most color cameras differ from the spectral responsivity of the human cone photoreceptors. Worse yet, the camera sensors are not within a linear transformation of the cone photopigments. As a result, lights that cause the same effect on the camera, that is lights that are visual matches when measured at the camera sensors, may be discriminable to the human observer. Conversely, there will be pairs of lights that are visual matches but that cause different responses in the camera sensors. I will return to discuss this topic when we return to discuss color appearance in <a href="chapter-9-color.html" class="quarto-xref"><span>Chapter 9</span></a>.</p>
</section>
</section>
<section id="color-appearance" class="level2" data-number="4.5">
<h2 data-number="4.5" class="anchored" data-anchor-id="color-appearance"><span class="header-section-number">4.5</span> Color Appearance</h2>
<p>Color-matching provides a standard of precision to strive for when we analyze the relationship between behavior and physiology. The work in color-matching is also important because it has had an impact well beyond basic science, into engineering and technology that touch our lives.</p>
<p>The success of color-matching and its explanation is so impressive, that there is a tendency to believe that color-matching explains more than it does. The theory and data of photopic color-matching provide a remarkably complete explanation of when two lights will match. But, the theory is silent about what the lights look like.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./wp-content/uploads/2012/02/colorXX.png" class="img-fluid figure-img" style="width:80.0%"></p>
<figcaption><strong>Color Plate 2</strong>. Color-matching does not predict color appearance. The X’s are physically the same (notice where they join) and thus have the same effect on the photopigments; but, their appearance differs. The photopigment responses at a point do not determine the color appearance at that point. Appearance instead depends on the spatial structure in the image. (Source: <span class="citation" data-cites="albers-painting1975">Albers (<a href="references.html#ref-albers-painting1975" role="doc-biblioref">1975</a>)</span>).</figcaption>
</figure>
</div>
<p>Often, students who are introduced to color-matching for the first time are surprised that the words brightness, saturation and hue never enter the discussion. The logic of the color-matching experiment, and what the color-matching experiment tells us about human vision, does not speak to color appearance. What we learn from color-matching is fundamental, but it is not everything we want to know. For many purposes we want to know An understanding of color-matching is necessary for an understanding color appearance; but, it is not a solution to the problem.</p>
<p>To emphasize the separation between color-matching and color appearance, consider the following experiment. Suppose that we form a color-match between two lights that are presented as a pair of crossing lines against one background. Such a pair is illustrated on the left hand side of Color Plate 2. On the left, the lines both appear gray. Now, move this pair of lines to a new background. Color-matching assures us that the two lights will continue to match one another as we move them about.</p>
<p>But we should not be assured that their appearance remains the same. For example, on the right of the figure we find that the pair of lights now have quite a different color appearance. By examining the point where the lines come together at the top of Color Plate 2, which is a painting by the artist Joseph Albers, you can see that the lines are physically identical on both sides of the painting.</p>
<p>Color-matching is different from color appearance. To build theories of color appearance we will need to incorporate experimental factors — such as the viewing context — that are not included in either the theory or experimental manipulations of the color-matching experiment. It is precisely because the important discoveries recounted in this chapter do not solve the problem of color appearance that the chapter is so oddly titled. We will review the topic of color in <a href="chapter-9-color.html" class="quarto-xref"><span>Chapter 9</span></a>.</p>



<div id="refs" class="references csl-bib-body hanging-indent" role="list" style="display: none">
<div id="ref-albers-painting1975" class="csl-entry" role="listitem">
Albers J (1975) Interaction of color: Revised edition. Yale University Press
</div>
<div id="ref-baylorphotoreceptorsignalsvision1987" class="csl-entry" role="listitem">
Baylor DA (1987) <a href="https://www.ncbi.nlm.nih.gov/pubmed/3026986">Photoreceptor signals and vision. <span>Proctor</span> lecture</a>. Investigative Ophthalmology and Visual Science 28:34–49
</div>
<div id="ref-baylor-macaque1987" class="csl-entry" role="listitem">
Baylor DA, Nunn BJ, Schnapf JL (1987) Spectral sensitivity of cones of the monkey macaca fascicularis. J Physiology 390:145–160. <a href="https://doi.org/10.1113/jphysiol.1987.sp016691">https://doi.org/10.1113/jphysiol.1987.sp016691</a>
</div>
<div id="ref-devaloisjacobs1971" class="csl-entry" role="listitem">
De Valois RL, Jacobs GH (1971) Vision. Behavior of Nonhuman Primates 107–157
</div>
<div id="ref-hubbard-wald1951" class="csl-entry" role="listitem">
Hubbard R, Wald G (1951) The mechanism of rhodopsin synthesis. Proceedings of the National Academy of Sciences of the United States of America 37:69–79
</div>
<div id="ref-judd1951a-visualstimulus" class="csl-entry" role="listitem">
Judd DB (1951) Basic correlates of the visual stimulus. In: Stevens SS (ed) Handbook of experimental psychology. Wiley, pp 811–867
</div>
<div id="ref-judd-wyszecki1975" class="csl-entry" role="listitem">
Judd DB, Wyszecki G (1975) Color in business science and industry, 3rd edn. Wiley-Interscience
</div>
<div id="ref-kalmus1965" class="csl-entry" role="listitem">
Kalmus H (1965) Diagnosis and genetics of defective colour vision. Pergamon Press, Oxford
</div>
<div id="ref-merbs1992-cones" class="csl-entry" role="listitem">
Merbs SL, Nathans J (1992) Absorption spectra of human cone pigments. Nature 356:433–435
</div>
<div id="ref-naka-rushton1966" class="csl-entry" role="listitem">
Naka K-I, Rushton WAH (1966) An attempt to analyse colour reception by electrophysiology. J Physiol 185:625–660
</div>
<div id="ref-nathans1992" class="csl-entry" role="listitem">
Nathans J, Merbs SL, Sung C-H, et al (1992) Molecular genetics of human visual pigments. 26:403–424
</div>
<div id="ref-neitz1993-moreconepigments" class="csl-entry" role="listitem">
Neitz J, Neitz M, Jacobs GH (1993) More than three different cone pigments among people with normal color vision. Vision Research 33:117–122
</div>
<div id="ref-newton1984" class="csl-entry" role="listitem">
Newton I (1984) The optical papers of isaac newton vol. <span>I</span>: <span>The</span> optical iectures 1670-1672. Cambridge University Press, Cambridge
</div>
<div id="ref-pokorny1979-book" class="csl-entry" role="listitem">
Pokorny JS, Smith V, Verriest G, Pinckers A (1979) Congenital and acquired color vision defects. Grune; Stratton, NY
</div>
<div id="ref-rushton1965-rodsensitivity" class="csl-entry" role="listitem">
Rushton WAH (1965) The sensitivity of rods under illumination. Journal of Physiology 178:141–160
</div>
<div id="ref-stiles-colourmatching1959" class="csl-entry" role="listitem">
Stiles WS, Burch JM (1959) <span>NPL</span> colour-matching investigation: <span>Final</span> report (1958). Optica Acta 6:1–26
</div>
<div id="ref-wald1968-molvisualexcit" class="csl-entry" role="listitem">
Wald G (1968) The molecular basis of visual excitation. Nature 219:800–807. https://doi.org/<a href="https://doi.org/10.1038/219800a0">https://doi.org/10.1038/219800a0</a>
</div>
<div id="ref-wald1958-humanrhodopsin" class="csl-entry" role="listitem">
Wald G, Brown PK (1958) Human rhodopsin. Science 127:222–226
</div>
<div id="ref-wyszeckicolorscienceconcepts1982" class="csl-entry" role="listitem">
Wyszecki G, Stiles WS (1982) Color <span>Science</span>: <span>Concepts</span> and <span>Methods</span>, <span>Quantitative Data</span> and <span>Formulae</span>, 2nd edn. John Wiley &amp; Sons, New York
</div>
</div>
</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>Color appearance is not a simple consequence of the spectral power distribution of the incident light. We will discuss color appearance broadly in <a href="chapter-9-color.html" class="quarto-xref"><span>Chapter 9</span></a>.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>Changing the sign of the primary intensity is a trivial matter for the theorist. It is a nuisance in the laboratory, however, and usually impossible in technological applications such as color displays. Thus, the issue of selecting primaries to minimize the number of times we must make this adjustment is of great practical interest.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>After correcting for the absorptions by the lens and inert pigments in the eye.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./chapter-3-the-photoreceptor-mosaic.html" class="pagination-link" aria-label="The Photoreceptor Mosaic">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">The Photoreceptor Mosaic</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./part-2-image-representation.html" class="pagination-link" aria-label="Introduction to Image Representation">
        <span class="nav-page-text">Introduction to Image Representation</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>